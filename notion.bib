@inproceedings{bjerva-etal-2020-sigtyp,
    title = "{SIGTYP} 2020 Shared Task: Prediction of Typological Features",
    author = "Bjerva, Johannes  and
      Salesky, Elizabeth  and
      Mielke, Sabrina J.  and
      Chaudhary, Aditi  and
      Celano, Giuseppe G. A.  and
      Ponti, Edoardo Maria  and
      Vylomova, Ekaterina  and
      Cotterell, Ryan  and
      Augenstein, Isabelle",
    booktitle = "Proceedings of the Second Workshop on Computational Research in Linguistic Typology",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.sigtyp-1.1",
    doi = "10.18653/v1/2020.sigtyp-1.1",
    pages = "1--11",
    abstract = "Typological knowledge bases (KBs) such as WALS (Dryer and Haspelmath, 2013) contain information about linguistic properties of the world{'}s languages. They have been shown to be useful for downstream applications, including cross-lingual transfer learning and linguistic probing. A major drawback hampering broader adoption of typological KBs is that they are sparsely populated, in the sense that most languages only have annotations for some features, and skewed, in that few features have wide coverage. As typological features often correlate with one another, it is possible to predict them and thus automatically populate typological KBs, which is also the focus of this shared task. Overall, the task attracted 8 submissions from 5 teams, out of which the most successful methods make use of such feature correlations. However, our error analysis reveals that even the strongest submitted systems struggle with predicting feature values for languages where few features are known.",
}

@article{Hart1994ToDS,
  title={To decode short cryptograms},
  author={George W. Hart},
  journal={Commun. ACM},
  year={1994},
  volume={37},
  pages={102-108},
  url={https://www.cs.rochester.edu/~brown/Crypto/reading/ShortCrypts.pdf},
}

@article{Olson2007RobustDA,
  title={Robust Dictionary Attack of Short Simple Substitution Ciphers},
  author={Edwin Olson},
  journal={Cryptologia},
  year={2007},
  volume={31},
  pages={332 - 342},
  abstract={Simple substitution ciphers are a class of puzzles often found in newspapers, in which each plaintext letter is mapped to a fixed ciphertext letter and spaces are preserved. In this article, a system for automatically solving them is described even when the ciphertext is too short for statistical analysis, and when the puzzle contains non-dictionary words. The approach is based around a dictionary attack; several important performance optimizations are described as well as effective techniques for dealing with non-dictionary words. Quantitative performance results for several variations of the approach and two other implementations are presented.},
  url={https://april.eecs.umich.edu/media/pdfs/olson2007crypt.pdf},
}

@inproceedings{Oranchak2008EvolutionaryAF,
  title={Evolutionary algorithm for decryption of monoalphabetic homophonic substitution ciphers encoded as constraint satisfaction problems},
  author={David Oranchak},
  booktitle={Annual Conference on Genetic and Evolutionary Computation},
  year={2008},
  url={http://gpbib.cs.ucl.ac.uk/gecco2008/docs/p1717.pdf},
}

@inproceedings {eacl2023,
       title = "Decipherment as Regression: Solving Historical Substitution Ciphers by Learning Symbol Recurrence Relations",
       author = "Kambhatla, Nishant and Born, Logan  and Sarkar, Anoop",
       booktitle = "Findings of the 17th Conference of the European Chapter of the Association for Computational Linguistics: EACL 2023 Findings",
       month = jan,
       year = "2023",
       address = "Dubrovnik, Croatia",
       publisher = "Association for Computational Linguistics",
       url = "https://aclanthology.org/",
       abstract = "Solving substitution ciphers involves mapping sequences of cipher symbols to fluent text in a target language. This has conventionally been formulated as a search problem, to find the decipherment key using a character-level language model to constrain the search space. This work instead frames decipherment as a sequence prediction task, using a Transformer-based causal language model to learn recurrences between characters in a ciphertext. We introduce a novel technique for transcribing arbitrary substitution ciphers into a common \textit { recurrence encoding } . By leveraging this technique, we (i) create a large synthetic dataset of homophonic ciphers using random keys, and (ii) train a decipherment model that predicts the plaintext sequence given a recurrence-encoded ciphertext. Our method achieves strong results on synthetic 1:1 and homophonic ciphers, and cracks several real historic homophonic ciphers. Our analysis shows that the model learns recurrence relations between cipher symbols and recovers decipherment keys in its self-attention."
    } 

@inproceedings{mccarthy-etal-2020-measuring,
    title = "Measuring the Similarity of Grammatical Gender Systems by Comparing Partitions",
    author = "McCarthy, Arya D.  and
      Williams, Adina  and
      Liu, Shijia  and
      Yarowsky, David  and
      Cotterell, Ryan",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.456",
    doi = "10.18653/v1/2020.emnlp-main.456",
    pages = "5664--5675",
    abstract = "A grammatical gender system divides a lexicon into a small number of relatively fixed grammatical categories. How similar are these gender systems across languages? To quantify the similarity, we define gender systems extensionally, thereby reducing the problem of comparisons between languages{'} gender systems to cluster evaluation. We borrow a rich inventory of statistical tools for cluster evaluation from the field of community detection (Driver and Kroeber, 1932; Cattell, 1945), that enable us to craft novel information theoretic metrics for measuring similarity between gender systems. We first validate our metrics, then use them to measure gender system similarity in 20 languages. We then ask whether our gender system similarities alone are sufficient to reconstruct historical relationships between languages. Towards this end, we make phylogenetic predictions on the popular, but thorny, problem from historical linguistics of inducing a phylogenetic tree over extant Indo-European languages. Of particular interest, languages on the same branch of our phylogenetic tree are notably similar, whereas languages from separate branches are no more similar than chance.",
}

@inproceedings{rama-etal-2020-probing,
    title = "Probing Multilingual {BERT} for Genetic and Typological Signals",
    author = "Rama, Taraka  and
      Beinborn, Lisa  and
      Eger, Steffen",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.105",
    doi = "10.18653/v1/2020.coling-main.105",
    pages = "1214--1228",
    abstract = "We probe the layers in multilingual BERT (mBERT) for phylogenetic and geographic language signals across 100 languages and compute language distances based on the mBERT representations. We 1) employ the language distances to infer and evaluate language trees, finding that they are close to the reference family tree in terms of quartet tree distance, 2) perform distance matrix regression analysis, finding that the language distances can be best explained by phylogenetic and worst by structural factors and 3) present a novel measure for measuring diachronic meaning stability (based on cross-lingual representation variability) which correlates significantly with published ranked lists based on linguistic approaches. Our results contribute to the nascent field of typological interpretability of cross-lingual text representations.",
}

@inproceedings{dutta-chowdhury-etal-2020-understanding,
    title = "Understanding Translationese in Multi-view Embedding Spaces",
    author = "Dutta Chowdhury, Koel  and
      Espa{\~n}a-Bonet, Cristina  and
      van Genabith, Josef",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.532",
    doi = "10.18653/v1/2020.coling-main.532",
    pages = "6056--6062",
    abstract = "Recent studies use a combination of lexical and syntactic features to show that footprints of the source language remain visible in translations, to the extent that it is possible to predict the original source language from the translation. In this paper, we focus on embedding-based semantic spaces, exploiting departures from isomorphism between spaces built from original target language and translations into this target language to predict relations between languages in an unsupervised way. We use different views of the data {---} words, parts of speech, semantic tags and synsets {---} to track translationese. Our analysis shows that (i) semantic distances between original target language and translations into this target language can be detected using the notion of isomorphism, (ii) language family ties with characteristics similar to linguistically motivated phylogenetic trees can be inferred from the distances and (iii) with delexicalised embeddings exhibiting source-language interference most significantly, other levels of abstraction display the same tendency, indicating the lexicalised results to be not {``}just{''} due to possible topic differences between original and translated texts. To the best of our knowledge, this is the first time departures from isomorphism between embedding spaces are used to track translationese.",
}

@inproceedings{dutta-chowdhury-etal-2021-tracing,    title = "Tracing Source Language Interference in Translation with Graph-Isomorphism Measures",    author = "Dutta Chowdhury, Koel  and      Espa{\~n}a-Bonet, Cristina  and      van Genabith, Josef",    booktitle = "Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)",    month = sep,    year = "2021",    address = "Held Online",    publisher = "INCOMA Ltd.",    url = "https://aclanthology.org/2021.ranlp-1.43",    pages = "375--385",    abstract = "Previous research has used linguistic features to show that translations exhibit traces of source language interference and that phylogenetic trees between languages can be reconstructed from the results of translations into the same language. Recent research has shown that instances of translationese (source language interference) can even be detected in embedding spaces, comparing embeddings spaces of original language data with embedding spaces resulting from translations into the same language, using a simple Eigenvector-based divergence from isomorphism measure. To date, it remains an open question whether alternative graph-isomorphism measures can produce better results. In this paper, we (i) explore Gromov-Hausdorff distance, (ii) present a novel spectral version of the Eigenvector-based method, and (iii) evaluate all approaches against a broad linguistic typological database (URIEL). We show that language distances resulting from our spectral isomorphism approaches can reproduce genetic trees on a par with previous work without requiring any explicit linguistic information and that the results can be extended to non-Indo-European languages. Finally, we show that the methods are robust under a variety of modeling conditions.",}

@inproceedings{rabinovich-etal-2017-found,
    title = "Found in Translation: Reconstructing Phylogenetic Language Trees from Translations",
    author = "Rabinovich, Ella  and
      Ordan, Noam  and
      Wintner, Shuly",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1049",
    doi = "10.18653/v1/P17-1049",
    pages = "530--540",
    abstract = "Translation has played an important role in trade, law, commerce, politics, and literature for thousands of years. Translators have always tried to be invisible; ideal translations should look as if they were written originally in the target language. We show that traces of the source language remain in the translation product to the extent that it is possible to uncover the history of the source language by looking only at the translation. Specifically, we automatically reconstruct phylogenetic language trees from monolingual texts (translated from several source languages). The signal of the source language is so powerful that it is retained even after two phases of translation. This strongly indicates that source language interference is the most dominant characteristic of translated texts, overshadowing the more subtle signals of universal properties of translation.",
}

@inproceedings{yu-etal-2021-language,    title = "Language Embeddings for Typology and Cross-lingual Transfer Learning",    author = "Yu, Dian  and      He, Taiqi  and      Sagae, Kenji",    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",    month = aug,    year = "2021",    address = "Online",    publisher = "Association for Computational Linguistics",    url = "https://aclanthology.org/2021.acl-long.560",    doi = "10.18653/v1/2021.acl-long.560",    pages = "7210--7225",    abstract = "Cross-lingual language tasks typically require a substantial amount of annotated data or parallel translation data. We explore whether language representations that capture relationships among languages can be learned and subsequently leveraged in cross-lingual tasks without the use of parallel data. We generate dense embeddings for 29 languages using a denoising autoencoder, and evaluate the embeddings using the World Atlas of Language Structures (WALS) and two extrinsic tasks in a zero-shot setting: cross-lingual dependency parsing and cross-lingual natural language inference.",}

@article{Zhao2020ConstructingAF,
  title={Constructing a Family Tree of Ten Indo-European Languages with Delexicalized Cross-linguistic Transfer Patterns},
  author={Yuanyuan Zhao and Weiwei Sun and Xiaojun Wan},
  journal={ArXiv},
  year={2020},
  volume={abs/2007.09076}
}

@inproceedings{oncevay-etal-2020-bridging,
    title = "Bridging Linguistic Typology and Multilingual Machine Translation with Multi-View Language Representations",
    author = "Oncevay, Arturo  and
      Haddow, Barry  and
      Birch, Alexandra",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.187",
    doi = "10.18653/v1/2020.emnlp-main.187",
    pages = "2391--2406",
    abstract = "Sparse language vectors from linguistic typology databases and learned embeddings from tasks like multilingual machine translation have been investigated in isolation, without analysing how they could benefit from each other{'}s language characterisation. We propose to fuse both views using singular vector canonical correlation analysis and study what kind of information is induced from each source. By inferring typological features and language phylogenies, we observe that our representations embed typology and strengthen correlations with language relationships. We then take advantage of our multi-view language vector space for multilingual machine translation, where we achieve competitive overall translation accuracy in tasks that require information about language similarities, such as language clustering and ranking candidates for multilingual transfer. With our method, we can easily project and assess new languages without expensive retraining of massive multilingual or ranking models, which are major disadvantages of related approaches.",
}

@inproceedings{scholivet-etal-2019-typological,
    title = "Typological Features for Multilingual Delexicalised Dependency Parsing",
    author = "Scholivet, Manon  and
      Dary, Franck  and
      Nasr, Alexis  and
      Favre, Benoit  and
      Ramisch, Carlos",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1393",
    doi = "10.18653/v1/N19-1393",
    pages = "3919--3930",
    abstract = "The existence of universal models to describe the syntax of languages has been debated for decades. The availability of resources such as the Universal Dependencies treebanks and the World Atlas of Language Structures make it possible to study the plausibility of universal grammar from the perspective of dependency parsing. Our work investigates the use of high-level language descriptions in the form of typological features for multilingual dependency parsing. Our experiments on multilingual parsing for 40 languages show that typological information can indeed guide parsers to share information between similar languages beyond simple language identification.",
}

@article{beinborn-choenni-2020-semantic,
    title = "Semantic Drift in Multilingual Representations",
    author = "Beinborn, Lisa  and
      Choenni, Rochelle",
    journal = "Computational Linguistics",
    volume = "46",
    number = "3",
    month = sep,
    year = "2020",
    url = "https://aclanthology.org/2020.cl-3.2",
    doi = "10.1162/coli_a_00382",
    pages = "571--603",
    abstract = "Multilingual representations have mostly been evaluated based on their performance on specific tasks. In this article, we look beyond engineering goals and analyze the relations between languages in computational representations. We introduce a methodology for comparing languages based on their organization of semantic concepts. We propose to conduct an adapted version of representational similarity analysis of a selected set of concepts in computational multilingual representations. Using this analysis method, we can reconstruct a phylogenetic tree that closely resembles those assumed by linguistic experts. These results indicate that multilingual distributional representations that are only trained on monolingual text and bilingual dictionaries preserve relations between languages without the need for any etymological information. In addition, we propose a measure to identify semantic drift between language families. We perform experiments on word-based and sentence-based multilingual models and provide both quantitative results and qualitative examples. Analyses of semantic drift in multilingual representations can serve two purposes: They can indicate unwanted characteristics of the computational models and they provide a quantitative means to study linguistic phenomena across languages.",
}

@article{bjerva-etal-2019-language,
    title = "What Do Language Representations Really Represent?",
    author = {Bjerva, Johannes  and
      {\"O}stling, Robert  and
      Veiga, Maria Han  and
      Tiedemann, J{\"o}rg  and
      Augenstein, Isabelle},
    journal = "Computational Linguistics",
    volume = "45",
    number = "2",
    month = jun,
    year = "2019",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/J19-2006",
    doi = "10.1162/coli_a_00351",
    pages = "381--389",
    abstract = "A neural language model trained on a text corpus can be used to induce distributed representations of words, such that similar words end up with similar representations. If the corpus is multilingual, the same model can be used to learn distributed representations of languages, such that similar languages end up with similar representations. We show that this holds even when the multilingual corpus has been translated into English, by picking up the faint signal left by the source languages. However, just as it is a thorny problem to separate semantic from syntactic similarity in word representations, it is not obvious what type of similarity is captured by language representations. We investigate correlations and causal relationships between language representations learned from translations on one hand, and genetic, geographical, and several levels of structural similarity between languages on the other. Of these, structural similarity is found to correlate most strongly with language representation similarity, whereas genetic relationships{---}a convenient benchmark used for evaluation in previous work{---}appears to be a confounding factor. Apart from implications about translation effects, we see this more generally as a case where NLP and linguistic typology can interact and benefit one another.",
}

@inproceedings{Oncevay2019TowardsAM,
  title={Towards a Multi-view Language Representation: A Shared Space of Discrete and Continuous Language Features},
  author={Arturo Oncevay and Barry Haddow and Alexandra Birch},
  year={2019},
  url={https://www.semanticscholar.org/paper/Towards-a-Multi-view-Language-Representation%3A-A-of-Oncevay-Haddow/72d3b4fd389d0e80e57386aa6c98b8c7a2ad1e16},
}

@article{rabinovich-etal-2018-native,
    title = "Native Language Cognate Effects on Second Language Lexical Choice",
    author = "Rabinovich, Ella  and
      Tsvetkov, Yulia  and
      Wintner, Shuly",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "6",
    year = "2018",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q18-1024",
    doi = "10.1162/tacl_a_00024",
    pages = "329--342",
    abstract = "We present a computational analysis of cognate effects on the spontaneous linguistic productions of advanced non-native speakers. Introducing a large corpus of highly competent non-native English speakers, and using a set of carefully selected lexical items, we show that the lexical choices of non-natives are affected by cognates in their native language. This effect is so powerful that we are able to reconstruct the phylogenetic language tree of the Indo-European language family solely from the frequencies of specific lexical items in the English of authors with various native languages. We quantitatively analyze non-native lexical choice, highlighting cognate facilitation as one of the important phenomena shaping the language of non-native speakers.",
}

@inproceedings{koehn-knight-2002-learning,
    title = "Learning a Translation Lexicon from Monolingual Corpora",
    author = "Koehn, Philipp  and
      Knight, Kevin",
    booktitle = "Proceedings of the {ACL}-02 Workshop on Unsupervised Lexical Acquisition",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W02-0902",
    doi = "10.3115/1118627.1118629",
    pages = "9--16",
    abstract = "This paper presents work on the task of constructing a word-level translation lexicon purely from unrelated monolingual corpora. We combine various clues such as cognates, similar context, preservation of word similarity, and word frequency. Experimental results for the construction of a German-English noun lexicon are reported. Noun translation accuracy of 39% scored against a parallel test corpus could be achieved.",
}
@inproceedings{bouchard-etal-2007-probabilistic,
    title = "A Probabilistic Approach to Diachronic Phonology",
    author = "Bouchard, Alexandre  and
      Liang, Percy  and
      Griffiths, Thomas  and
      Klein, Dan",
    booktitle = "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL})",
    month = jun,
    year = "2007",
    address = "Prague, Czech Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D07-1093",
    pages = "887--896",
}

@inproceedings{hauer2021HistoCrypt-dorabella,
 abstract = {The Dorabella cipher is a symbolic message written in 1897 by English composer Edward Elgar. We analyze the cipher using modern computational and statistical techniques. We consider several open questions: Is the underlying message natural language text or music? If it is language, what is the most likely language? Is Dorabella a simple substitution cipher? If so, why has nobody managed to produce a plausible decipherment? Are some unusual-looking patterns in the cipher likely to occur by chance? Can state-of-the-art algorithmic solvers decipher at least some words of the message? This work is intended as a contribution towards finding answers to these questions.},
 accepted = {2021-04-23},
 author = {Bradley Hauer and Colin Choi and Anirudh Sundar and Abram Hindle and Scott Smallwood and Grzegorz Kondrak},
 authors = {Bradley Hauer, Colin Choi, Anirudh Sundar, Abram Hindle, Scott Smallwood, Grzegorz Kondrak},
 booktitle = {The International Conference on Historical Cryptology (HistoCrypt 2021)},
 code = {hauer2021HistoCrypt-dorabella},
 date = {2021-09-20},
 funding = {NSERC Discovery},
 pagerange = {1--10},
 pages = {1--10},
 role = {Co-author},
 title = {Experimental Analysis of the Dorabella Cipher with Statistical Language Models},
 type = {inproceedings},
 url = {http://softwareprocess.ca/pubs/hauer2021HistoCrypt-dorabella.pdf},
 venue = {The International Conference on Historical Cryptology (HistoCrypt 2021)},
 year = {2021}
}
@inproceedings{gambardella-etal-2022-identifying,
    title = "Identifying Cleartext in Historical Ciphers",
    author = "Gambardella, Maria-Elena  and
      Megyesi, Beata  and
      Pettersson, Eva",
    booktitle = "Proceedings of the Second Workshop on Language Technologies for Historical and Ancient Languages",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lt4hala-1.1",
    pages = "1--9",
    abstract = "In historical encrypted sources we can find encrypted text sequences, also called ciphertext, as well as non-encrypted cleartexts written in a known language. While most of the cryptanalysis focuses on the decryption of ciphertext, cleartext is often overlooked although it can give us important clues about the historical interpretation and contextualisation of the manuscript. In this paper, we investigate to what extent we can automatically distinguish cleartext from ciphertext in historical ciphers and to what extent we are able to identify its language. The problem is challenging as cleartext sequences in ciphers are often short, up to a few words, in different languages due to historical code-switching. To identify the sequences and the language(s), we chose a rule-based approach and run 7 different models using historical language models on various ciphertexts.",
}
@inproceedings{corazza-etal-2022-contextual,
    title = "Contextual Unsupervised Clustering of Signs for Ancient Writing Systems",
    author = "Corazza, Michele  and
      Tamburini, Fabio  and
      Val{\'e}rio, Miguel  and
      Ferrara, Silvia",
    booktitle = "Proceedings of the Second Workshop on Language Technologies for Historical and Ancient Languages",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lt4hala-1.12",
    pages = "84--93",
    abstract = "The application of machine learning techniques to ancient writing systems is a relatively new idea, and it poses interesting challenges for researchers. One particularly challenging aspect is the scarcity of data for these scripts, which contrasts with the large amounts of data usually available when applying neural models to computational linguistics and other fields. For this reason, any method that attempts to work on ancient scripts needs to be ad-hoc and consider paleographic aspects, in addition to computational ones. Considering the peculiar characteristics of the script that we used is therefore be a crucial part of our work, as any solution needs to consider the particular nature of the writing system that it is applied to. In this work we propose a preliminary evaluation of a novel unsupervised clustering method on Cypro-Greek syllabary, a writing system from Cyprus. This evaluation shows that our method improves clustering performance using information about the attested sequences of signs in combination with an unsupervised model for images, with the future goal of applying the methodology to undeciphered writing systems from a related and typologically similar script.",
}
@inproceedings{vertan-prager-2022-inscription,
    title = "From Inscription to Semi-automatic Annotation of {M}aya Hieroglyphic Texts",
    author = "Vertan, Cristina  and
      Prager, Christian",
    booktitle = "Proceedings of the Second Workshop on Language Technologies for Historical and Ancient Languages",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lt4hala-1.16",
    pages = "114--118",
    abstract = "The Maya script is the only readable autochthonous writing system of the Americas and consists of more than 1000 word signs and syllables. It is only partially deciphered and is the subject of the project {``}Text Database and Dictionary of the Classic Maya{''} . Texts are recorded in TEI XML and on the basis of a digital sign and graph catalog, which are stored in the TextGrid virtual repository. Due to the state of decipherment, it is not possible to record hieroglyphic texts directly in phonemically transliterated values. The texts are therefore documented numerically using numeric sign codes based on Eric Thompson{'}s catalog of the Maya script. The workflow for converting numerical transliteration into textual form involves several steps, with variable solutions possible at each step. For this purpose, the authors have developed ALMAH {``}Annotator for the Linguistic Analysis of Maya Hieroglyphs{''}. The tool is a client application and allows semi-automatic generation of phonemic transliteration from numerical transliteration and enables multi-step linguistic annotation. Alternative readings can be entered, and two or more decipherment proposals can be processed in parallel. ALMAH is implemented in JAVA, is based on a graph-data model, and has a user-friendly interface.",
}
@inproceedings{chi-etal-2022-zinet,
    title = "{Z}i{N}et: {L}inking {C}hinese Characters Spanning Three Thousand Years",
    author = "Chi, Yang  and
      Giunchiglia, Fausto  and
      Shi, Daqian  and
      Diao, Xiaolei  and
      Li, Chuntao  and
      Xu, Hao",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.242",
    doi = "10.18653/v1/2022.findings-acl.242",
    pages = "3061--3070",
    abstract = "Modern Chinese characters evolved from 3,000 years ago. Up to now, tens of thousands of glyphs of ancient characters have been discovered, which must be deciphered by experts to interpret unearthed documents. Experts usually need to compare each ancient character to be examined with similar known ones in whole historical periods. However, it is inevitably limited by human memory and experience, which often cost a lot of time but associations are limited to a small scope. To help researchers discover glyph similar characters, this paper introduces ZiNet, the first diachronic knowledge base describing relationships and evolution of Chinese characters and words. In addition, powered by the knowledge of radical systems in ZiNet, this paper introduces glyph similarity measurement between ancient Chinese characters, which could capture similar glyph pairs that are potentially related in origins or semantics. Results show strong positive correlations between scores from the method and from human experts. Finally, qualitative analysis and implicit future applications are presented.",
}
@inproceedings{aldarrab-may-2022-segmenting,
    title = "Segmenting Numerical Substitution Ciphers",
    author = "Aldarrab, Nada  and
      May, Jonathan",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.44",
    pages = "706--714",
    abstract = "Deciphering historical substitution ciphers is a challenging problem. Example problems that have been previously studied include detecting cipher type, detecting plaintext language, and acquiring the substitution key for segmented ciphers. However, attacking unsegmented ciphers is still a challenging task. Segmentation (i.e. finding substitution units) is essential for cracking those ciphers. In this work, we propose the first automatic methods to segment those ciphers using Byte Pair Encoding (BPE) and unigram language models. Our methods achieve an average segmentation error of 2{\%} on 100 randomly-generated monoalphabetic ciphers and 27{\%} on 3 real historical homophonic ciphers. We also propose a method for solving non-deterministic ciphers with existing keys using a lattice and a pretrained language model. Our method leads to the full solution of the IA cipher; a real historical cipher that has not been fully solved until this work.",
}
@inproceedings{wang-etal-2022-breaking,
    title = "Breaking the Representation Bottleneck of {C}hinese Characters: Neural Machine Translation with Stroke Sequence Modeling",
    author = "Wang, Zhijun  and
      Liu, Xuebo  and
      Zhang, Min",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.434",
    pages = "6473--6484",
    abstract = "Existing research generally treats Chinese character as a minimum unit for representation. However, such Chinese character representation will suffer two bottlenecks: 1) Learning bottleneck, the learning cannot benefit from its rich internal features (e.g., radicals and strokes); and 2) Parameter bottleneck, each individual character has to be represented by a unique vector. In this paper, we introduce a novel representation method for Chinese characters to break the bottlenecks, namely StrokeNet, which represents a Chinese character by a Latinized stroke sequence (e.g., {``}凹 (concave){''} to {``}ajaie{''} and {``}凸 (convex){''} to {``}aeaqe{''}). Specifically, StrokeNet maps each stroke to a specific Latin character, thus allowing similar Chinese characters to have similar Latin representations. With the introduction of StrokeNet to neural machine translation (NMT), many powerful but not applicable techniques to non-Latin languages (e.g., shared subword vocabulary learning and ciphertext-based data augmentation) can now be perfectly implemented. Experiments on the widely-used NIST Chinese-English, WMT17 Chinese-English and IWSLT17 Japanese-English NMT tasks show that StrokeNet can provide a significant performance boost over the strong baselines with fewer model parameters, achieving 26.5 BLEU on the WMT17 Chinese-English task which is better than any previously reported results without using monolingual data. Code and scripts are freely available at https://github.com/zjwang21/StrokeNet.",
}
@inproceedings{born-etal-2022-sequence,
    title = "Sequence Models for Document Structure Identification in an Undeciphered Script",
    author = "Born, Logan  and
      Monroe, M.  and
      Kelley, Kathryn  and
      Sarkar, Anoop",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.620",
    pages = "9111--9121",
    abstract = "This work describes the first thorough analysis of {``}header{''} signs in proto-Elamite, an undeciphered script from 3100-2900 BCE. Headers are a category of signs which have been provisionally identified through painstaking manual analysis of this script by domain experts. We use unsupervised neural and statistical sequence modeling techniques to provide new and independent evidence for the existence of headers, without supervision from domain experts. Having affirmed the existence of headers as a legitimate structural feature, we next arrive at a richer understanding of their possible meaning and purpose by (i) examining which features predict their presence; (ii) identifying correlations between these features and other document properties; and (iii) examining cases where these features predict the presence of a header in texts where domain experts do not expect one (or vice versa). We provide more concrete processes for labeling headers in this corpus and a clearer justification for existing intuitions about document structure in proto-Elamite.",
}
@inproceedings{kambhatla-etal-2022-cipherdaug,
    title = "{C}ipher{DA}ug: Ciphertext based Data Augmentation for Neural Machine Translation",
    author = "Kambhatla, Nishant  and
      Born, Logan  and
      Sarkar, Anoop",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.17",
    doi = "10.18653/v1/2022.acl-long.17",
    pages = "201--218",
    abstract = "We propose a novel data-augmentation technique for neural machine translation based on ROT-$k$ ciphertexts. ROT-$k$ is a simple letter substitution cipher that replaces a letter in the plaintext with the $k$th letter after it in the alphabet. We first generate multiple ROT-$k$ ciphertexts using different values of $k$ for the plaintext which is the source side of the parallel data. We then leverage this enciphered training data along with the original parallel data via multi-source training to improve neural machine translation. Our method, CipherDAug, uses a co-regularization-inspired training procedure, requires no external data sources other than the original training data, and uses a standard Transformer to outperform strong data augmentation techniques on several datasets by a significant margin. This technique combines easily with existing approaches to data augmentation, and yields particularly strong results in low-resource settings.",
}
@article{luo-etal-2021-deciphering,
    title = "Deciphering Undersegmented Ancient Scripts Using Phonetic Prior",
    author = "Luo, Jiaming  and
      Hartmann, Frederik  and
      Santus, Enrico  and
      Barzilay, Regina  and
      Cao, Yuan",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "9",
    year = "2021",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2021.tacl-1.5",
    doi = "10.1162/tacl_a_00354",
    pages = "69--81",
    abstract = "Most undeciphered lost languages exhibit two characteristics that pose significant decipherment challenges: (1) the scripts are not fully segmented into words; (2) the closest known language is not determined. We propose a decipherment model that handles both of these challenges by building on rich linguistic constraints reflecting consistent patterns in historical sound change. We capture the natural phonological geometry by learning character embeddings based on the International Phonetic Alphabet (IPA). The resulting generative framework jointly models word segmentation and cognate alignment, informed by phonological constraints. We evaluate the model on both deciphered languages (Gothic, Ugaritic) and an undeciphered one (Iberian). The experiments show that incorporating phonetic geometry leads to clear and consistent gains. Additionally, we propose a measure for language closeness which correctly identifies related languages for Gothic and Ugaritic. For Iberian, the method does not show strong evidence supporting Basque as a related language, concurring with the favored position by the current scholarship.1",
}
@inproceedings{hauer-etal-2021-dorabella-cipher,
    title = "Dorabella Cipher as Musical Inspiration",
    author = "Hauer, Bradley  and
      Choi, Colin  and
      Hindle, Abram  and
      Smallwood, Scott  and
      Kondrak, Grzegorz",
    booktitle = "Proceedings of the Workshop on Speech and Music Processing 2021",
    month = dec,
    year = "2021",
    address = "NIT Silchar, India",
    publisher = "NLP Association of India (NLPAI)",
    url = "https://aclanthology.org/2021.smp-1.5",
    pages = "33--38",
    abstract = "The Dorabella cipher is an encrypted note of English composer Edward Elgar, which has defied decipherment attempts for more than a century. While most proposed solutions are English texts, we investigate the hypothe- sis that Dorabella represents enciphered music. We weigh the evidence in favor of and against the hypothesis, devise a simplified music nota- tion, and attempt to reconstruct a melody from the cipher. Our tools are n-gram models of mu- sic which we validate on existing music cor- pora enciphered using monoalphabetic substi- tution. By applying our methods to Dorabella, we produce a decipherment with musical qual- ities, which is then transformed via artful com- position into a listenable melody. Far from ar- guing that the end result represents the only true solution, we instead frame the process of decipherment as part of the composition pro- cess.",
}
@inproceedings{born-etal-2021-compositionality,
    title = "Compositionality of Complex Graphemes in the Undeciphered {P}roto-{E}lamite Script using Image and Text Embedding Models",
    author = "Born, Logan  and
      Kelley, Kathryn  and
      Monroe, M. Willis  and
      Sarkar, Anoop",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.362",
    doi = "10.18653/v1/2021.findings-acl.362",
    pages = "4136--4146",
    abstract = "We introduce a language modeling architecture which operates over sequences of images, or over multimodal sequences of images with associated labels. We use this architecture alongside other embedding models to investigate a category of signs called complex graphemes (CGs) in the undeciphered protoElamite script. We argue that CGs have meanings which are at least partly compositional, and we discover novel rules governing the construction of CGs. We find that a language model over sign images produces more interpretable results than a model over text or over sign images and text, which suggests that the names given to signs may be obscuring signals in the corpus. Our results reveal previously unknown regularities in proto-Elamite sign use that can inform future decipherment efforts, and our image-aware language model provides a novel way to abstract away from biases introduced by human annotators.",
}
@inproceedings{aldarrab-may-2021-sequence,
    title = "Can Sequence-to-Sequence Models Crack Substitution Ciphers?",
    author = "Aldarrab, Nada  and
      May, Jonathan",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.561",
    doi = "10.18653/v1/2021.acl-long.561",
    pages = "7226--7235",
    abstract = "Decipherment of historical ciphers is a challenging problem. The language of the target plaintext might be unknown, and ciphertext can have a lot of noise. State-of-the-art decipherment methods use beam search and a neural language model to score candidate plaintext hypotheses for a given cipher, assuming the plaintext language is known. We propose an end-to-end multilingual model for solving simple substitution ciphers. We test our model on synthetic and real historical ciphers and show that our proposed method can decipher text without explicit language identification while still being robust to noise.",
}
@inproceedings{chu-etal-2020-learning,
    title = "{L}earning to {P}ronounce {C}hinese {W}ithout a {P}ronunciation {D}ictionary",
    author = "Chu, Christopher  and
      Fang, Scot  and
      Knight, Kevin",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.458",
    doi = "10.18653/v1/2020.emnlp-main.458",
    pages = "5687--5693",
    abstract = "We demonstrate a program that learns to pronounce Chinese text in Mandarin, without a pronunciation dictionary. From non-parallel streams of Chinese characters and Chinese pinyin syllables, it establishes a many-to-many mapping between characters and pronunciations. Using unsupervised methods, the program effectively deciphers writing into speech. Its token-level character-to-syllable accuracy is 89{\%}, which significantly exceeds the 22{\%} accuracy of prior work.",
}
@inproceedings{chu-etal-2020-solving,
    title = "{S}olving {H}istorical {D}ictionary {C}odes with a {N}eural {L}anguage {M}odel",
    author = "Chu, Christopher  and
      Valenti, Raphael  and
      Knight, Kevin",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.471",
    doi = "10.18653/v1/2020.emnlp-main.471",
    pages = "5845--5854",
    abstract = "We solve difficult word-based substitution codes by constructing a decoding lattice and searching that lattice with a neural language model. We apply our method to a set of enciphered letters exchanged between US Army General James Wilkinson and agents of the Spanish Crown in the late 1700s and early 1800s, obtained from the US Library of Congress. We are able to decipher 75.1{\%} of the cipher-word tokens correctly.",
}
@inproceedings{ryskina-etal-2020-phonetic,
    title = "Phonetic and Visual Priors for Decipherment of Informal {R}omanization",
    author = "Ryskina, Maria  and
      Gormley, Matthew R.  and
      Berg-Kirkpatrick, Taylor",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.737",
    doi = "10.18653/v1/2020.acl-main.737",
    pages = "8308--8319",
    abstract = "Informal romanization is an idiosyncratic process used by humans in informal digital communication to encode non-Latin script languages into Latin character sets found on common keyboards. Character substitution choices differ between users but have been shown to be governed by the same main principles observed across a variety of languages{---}namely, character pairs are often associated through phonetic or visual similarity. We propose a noisy-channel WFST cascade model for deciphering the original non-Latin script from observed romanized text in an unsupervised fashion. We train our model directly on romanized data from two languages: Egyptian Arabic and Russian. We demonstrate that adding inductive bias through phonetic and visual priors on character mappings substantially improves the model{'}s performance on both languages, yielding results much closer to the supervised skyline. Finally, we introduce a new dataset of romanized Russian, collected from a Russian social network website and partially annotated for our experiments.",
}
@inproceedings{pettersson-megyesi-2019-matching,
    title = "Matching Keys and Encrypted Manuscripts",
    author = "Pettersson, Eva  and
      Megyesi, Beata",
    booktitle = "Proceedings of the 22nd Nordic Conference on Computational Linguistics",
    month = sep # "{--}" # oct,
    year = "2019",
    address = "Turku, Finland",
    publisher = {Link{\"o}ping University Electronic Press},
    url = "https://aclanthology.org/W19-6126",
    pages = "253--261",
    abstract = "Historical cryptology is the study of historical encrypted messages aiming at their decryption by analyzing the mathematical, linguistic and other coding patterns and their historical context. In libraries and archives we can find quite a lot of ciphers, as well as keys describing the method used to transform the plaintext message into a ciphertext. In this paper, we present work on automatically mapping keys to ciphers to reconstruct the original plaintext message, and use language models generated from historical texts to guess the underlying plaintext language.",
}
@inproceedings{born-etal-2019-sign,
    title = "Sign Clustering and Topic Extraction in {P}roto-{E}lamite",
    author = "Born, Logan  and
      Kelley, Kate  and
      Kambhatla, Nishant  and
      Chen, Carolyn  and
      Sarkar, Anoop",
    booktitle = "Proceedings of the 3rd Joint {SIGHUM} Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature",
    month = jun,
    year = "2019",
    address = "Minneapolis, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-2516",
    doi = "10.18653/v1/W19-2516",
    pages = "122--132",
    abstract = "We describe a first attempt at using techniques from computational linguistics to analyze the undeciphered proto-Elamite script. Using hierarchical clustering, n-gram frequencies, and LDA topic models, we both replicate results obtained by manual decipherment and reveal previously-unobserved relationships between signs. This demonstrates the utility of these techniques as an aid to manual decipherment.",
}
@inproceedings{vig-2019-multiscale,
    title = "A Multiscale Visualization of Attention in the Transformer Model",
    author = "Vig, Jesse",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-3007",
    doi = "10.18653/v1/P19-3007",
    pages = "37--42",
    abstract = "The Transformer is a sequence model that forgoes traditional recurrent architectures in favor of a fully attention-based approach. Besides improving performance, an advantage of using attention is that it can also help to interpret a model by showing how the model assigns weight to different input elements. However, the multi-layer, multi-head attention mechanism in the Transformer model can be difficult to decipher. To make the model more accessible, we introduce an open-source tool that visualizes attention at multiple scales, each of which provides a unique perspective on the attention mechanism. We demonstrate the tool on BERT and OpenAI GPT-2 and present three example use cases: detecting model bias, locating relevant attention heads, and linking neurons to model behavior.",
}
@inproceedings{luo-etal-2019-neural,
    title = "Neural Decipherment via Minimum-Cost Flow: From {U}garitic to {L}inear {B}",
    author = "Luo, Jiaming  and
      Cao, Yuan  and
      Barzilay, Regina",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1303",
    doi = "10.18653/v1/P19-1303",
    pages = "3146--3155",
    abstract = "In this paper we propose a novel neural approach for automatic decipherment of lost languages. To compensate for the lack of strong supervision signal, our model design is informed by patterns in language change documented in historical linguistics. The model utilizes an expressive sequence-to-sequence model to capture character-level correspondences between cognates. To effectively train the model in unsupervised manner, we innovate the training procedure by formalizing it as a minimum-cost flow problem. When applied to decipherment of Ugaritic, we achieve 5{\%} absolute improvement over state-of-the-art results. We also report first automatic results in deciphering Linear B, a syllabic language related to ancient Greek, where our model correctly translates 67.3{\%} of cognates.",
}
@inproceedings{cardenas-etal-2019-grounded,
    title = "A Grounded Unsupervised Universal Part-of-Speech Tagger for Low-Resource Languages",
    author = "Cardenas, Ronald  and
      Lin, Ying  and
      Ji, Heng  and
      May, Jonathan",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1252",
    doi = "10.18653/v1/N19-1252",
    pages = "2428--2439",
    abstract = "Unsupervised part of speech (POS) tagging is often framed as a clustering problem, but practical taggers need to ground their clusters as well. Grounding generally requires reference labeled data, a luxury a low-resource language might not have. In this work, we describe an approach for low-resource unsupervised POS tagging that yields fully grounded output and requires no labeled training data. We find the classic method of Brown et al. (1992) clusters well in our use case and employ a decipherment-based approach to grounding. This approach presumes a sequence of cluster IDs is a {`}ciphertext{'} and seeks a POS tag-to-cluster ID mapping that will reveal the POS sequence. We show intrinsically that, despite the difficulty of the task, we obtain reasonable performance across a variety of languages. We also show extrinsically that incorporating our POS tagger into a name tagger leads to state-of-the-art tagging performance in Sinhalese and Kinyarwanda, two languages with nearly no labeled POS data available. We further demonstrate our tagger{'}s utility by incorporating it into a true {`}zero-resource{'} variant of the MALOPA (Ammar et al., 2016) dependency parser model that removes the current reliance on multilingual resources and gold POS tags for new languages. Experiments show that including our tagger makes up much of the accuracy lost when gold POS tags are unavailable.",
}
@inproceedings{qian-etal-2019-learning,
    title = "Learning to Decipher Hate Symbols",
    author = "Qian, Jing  and
      ElSherief, Mai  and
      Belding, Elizabeth  and
      Wang, William Yang",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1305",
    doi = "10.18653/v1/N19-1305",
    pages = "3006--3015",
    abstract = "Existing computational models to understand hate speech typically frame the problem as a simple classification task, bypassing the understanding of hate symbols (e.g., 14 words, kigy) and their secret connotations. In this paper, we propose a novel task of deciphering hate symbols. To do this, we leveraged the Urban Dictionary and collected a new, symbol-rich Twitter corpus of hate speech. We investigate neural network latent context models for deciphering hate symbols. More specifically, we study Sequence-to-Sequence models and show how they are able to crack the ciphers based on context. Furthermore, we propose a novel Variational Decipher and show how it can generalize better to unseen hate symbols in a more challenging testing setting.",
}
@inproceedings{wu-etal-2018-decipherment,
    title = "Decipherment for Adversarial Offensive Language Detection",
    author = "Wu, Zhelun  and
      Kambhatla, Nishant  and
      Sarkar, Anoop",
    booktitle = "Proceedings of the 2nd Workshop on Abusive Language Online ({ALW}2)",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-5119",
    doi = "10.18653/v1/W18-5119",
    pages = "149--159",
    abstract = "Automated filters are commonly used by online services to stop users from sending age-inappropriate, bullying messages, or asking others to expose personal information. Previous work has focused on rules or classifiers to detect and filter offensive messages, but these are vulnerable to cleverly disguised plaintext and unseen expressions especially in an adversarial setting where the users can repeatedly try to bypass the filter. In this paper, we model the disguised messages as if they are produced by encrypting the original message using an invented cipher. We apply automatic decipherment techniques to decode the disguised malicious text, which can be then filtered using rules or classifiers. We provide experimental results on three different datasets and show that decipherment is an effective tool for this task.",
}
@article{naim-etal-2018-feature,
    title = "Feature-Based Decipherment for Machine Translation",
    author = "Naim, Iftekhar  and
      Riley, Parker  and
      Gildea, Daniel",
    journal = "Computational Linguistics",
    volume = "44",
    number = "3",
    month = sep,
    year = "2018",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/J18-3006",
    doi = "10.1162/coli_a_00326",
    pages = "525--546",
    abstract = "Orthographic similarities across languages provide a strong signal for unsupervised probabilistic transduction (decipherment) for closely related language pairs. The existing decipherment models, however, are not well suited for exploiting these orthographic similarities. We propose a log-linear model with latent variables that incorporates orthographic similarity features. Maximum likelihood training is computationally expensive for the proposed log-linear model. To address this challenge, we perform approximate inference via Markov chain Monte Carlo sampling and contrastive divergence. Our results show that the proposed log-linear model with contrastive divergence outperforms the existing generative decipherment models by exploiting the orthographic features. The model both scales to large vocabularies and preserves accuracy in low- and no-resource contexts.",
}
@inproceedings{kambhatla-etal-2018-decipherment,
    title = "Decipherment of Substitution Ciphers with Neural Language Models",
    author = "Kambhatla, Nishant  and
      Mansouri Bigvand, Anahita  and
      Sarkar, Anoop",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1102",
    doi = "10.18653/v1/D18-1102",
    pages = "869--874",
    abstract = "Decipherment of homophonic substitution ciphers using language models is a well-studied task in NLP. Previous work in this topic scores short local spans of possible plaintext decipherments using n-gram language models. The most widely used technique is the use of beam search with n-gram language models proposed by Nuhn et al.(2013). We propose a beam search algorithm that scores the entire candidate plaintext at each step of the decipherment using a neural language model. We augment beam search with a novel rest cost estimation that exploits the prediction power of a neural language model. We compare against the state of the art n-gram based methods on many different decipherment tasks. On challenging ciphers such as the Beale cipher we provide significantly better error rates with much smaller beam sizes.",
}
@inproceedings{ge-etal-2018-fine,
    title = "Fine-grained Coordinated Cross-lingual Text Stream Alignment for Endless Language Knowledge Acquisition",
    author = "Ge, Tao  and
      Dou, Qing  and
      Ji, Heng  and
      Cui, Lei  and
      Chang, Baobao  and
      Sui, Zhifang  and
      Wei, Furu  and
      Zhou, Ming",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1271",
    doi = "10.18653/v1/D18-1271",
    pages = "2496--2506",
    abstract = "This paper proposes to study fine-grained coordinated cross-lingual text stream alignment through a novel information network decipherment paradigm. We use Burst Information Networks as media to represent text streams and present a simple yet effective network decipherment algorithm with diverse clues to decipher the networks for accurate text stream alignment. Experiments on Chinese-English news streams show our approach not only outperforms previous approaches on bilingual lexicon extraction from coordinated text streams but also can harvest high-quality alignments from large amounts of streaming data for endless language knowledge mining, which makes it promising to be a new paradigm for automatic language knowledge acquisition.",
}
@inproceedings{thaine-penn-2017-vowel,
    title = "Vowel and Consonant Classification through Spectral Decomposition",
    author = "Thaine, Patricia  and
      Penn, Gerald",
    booktitle = "Proceedings of the First Workshop on Subword and Character Level Models in {NLP}",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W17-4112",
    doi = "10.18653/v1/W17-4112",
    pages = "82--91",
    abstract = "We consider two related problems in this paper. Given an undeciphered alphabetic writing system or mono-alphabetic cipher, determine: (1) which of its letters are vowels and which are consonants; and (2) whether the writing system is a vocalic alphabet or an abjad. We are able to show that a very simple spectral decomposition based on character co-occurrences provides nearly perfect performance with respect to answering both question types.",
}
@inproceedings{ganesan-etal-2017-protein,
    title = "Protein Word Detection using Text Segmentation Techniques",
    author = "Ganesan, Devi  and
      Tendulkar, Ashish V.  and
      Chakraborti, Sutanu",
    booktitle = "{B}io{NLP} 2017",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada,",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W17-2330",
    doi = "10.18653/v1/W17-2330",
    pages = "238--246",
    abstract = "Literature in Molecular Biology is abundant with linguistic metaphors. There have been works in the past that attempt to draw parallels between linguistics and biology, driven by the fundamental premise that proteins have a language of their own. Since word detection is crucial to the decipherment of any unknown language, we attempt to establish a problem mapping from natural language text to protein sequences at the level of words. Towards this end, we explore the use of an unsupervised text segmentation algorithm to the task of extracting {``}biological words{''} from protein sequences. In particular, we demonstrate the effectiveness of using domain knowledge to complement data driven approaches in the text segmentation task, as well as in its biological counterpart. We also propose a novel extrinsic evaluation measure for protein words through protein family classification.",
}
@inproceedings{pourdamghani-knight-2017-deciphering,
    title = "Deciphering Related Languages",
    author = "Pourdamghani, Nima  and
      Knight, Kevin",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1266",
    doi = "10.18653/v1/D17-1266",
    pages = "2513--2518",
    abstract = "We present a method for translating texts between close language pairs. The method does not require parallel data, and it does not require the languages to be written in the same script. We show results for six language pairs: Afrikaans/Dutch, Bosnian/Serbian, Danish/Swedish, Macedonian/Bulgarian, Malaysian/Indonesian, and Polish/Belorussian. We report BLEU scores showing our method to outperform others that do not use parallel data.",
}
@article{hauer-kondrak-2016-decoding,
    title = "Decoding Anagrammed Texts Written in an Unknown Language and Script",
    author = "Hauer, Bradley  and
      Kondrak, Grzegorz",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "4",
    year = "2016",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q16-1006",
    doi = "10.1162/tacl_a_00084",
    pages = "75--86",
    abstract = "Algorithmic decipherment is a prime example of a truly unsupervised problem. The first step in the decipherment process is the identification of the encrypted language. We propose three methods for determining the source language of a document enciphered with a monoalphabetic substitution cipher. The best method achieves 97{\%} accuracy on 380 languages. We then present an approach to decoding anagrammed substitution ciphers, in which the letters within words have been arbitrarily transposed. It obtains the average decryption word accuracy of 93{\%} on a set of 50 ciphertexts in 5 languages. Finally, we report the results on the Voynich manuscript, an unsolved fifteenth century cipher, which suggest Hebrew as the language of the document.",
}
@inproceedings{peterson-fyshe-2016-poet,
    title = "Poet Admits // Mute Cypher: Beam Search to find Mutually Enciphering Poetic Texts",
    author = "Peterson, Cole  and
      Fyshe, Alona",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D16-1141",
    doi = "10.18653/v1/D16-1141",
    pages = "1339--1347",
    abstract = "The Xenotext Experiment implants poetry into an extremophile’s DNA, and uses that DNA to generate new poetry in a protein form. The molecular machinery of life requires that these two poems encipher each other under a symmetric substitution cipher. We search for ciphers which permit writing under the Xenotext constraints, incorporating ideas from cipher-cracking algorithms, and using n-gram data to assess a cipher’s “writability”. Our algorithm, Beam Verse, is a beam search which uses new heuristics to navigate the cipher-space. We find thousands of ciphers which score higher than successful ciphers used to write Xenotext constrained texts.",
}
@inproceedings{nuhn-etal-2015-unravel,
    title = "{UNRAVEL}{---}{A} Decipherment Toolkit",
    author = "Nuhn, Malte  and
      Schamper, Julian  and
      Ney, Hermann",
    booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
    month = jul,
    year = "2015",
    address = "Beijing, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P15-2090",
    doi = "10.3115/v1/P15-2090",
    pages = "549--553",
    abstract = "In this paper we present the UNRAVEL toolkit: It implements many of the recently published works on decipherment, including decipherment for deterministic ciphers like e.g. the ZODIAC-408 cipher and Part two of the BEALE ciphers, as well as decipherment of probabilistic ciphers and unsupervised training for machine translation. It also includes data and example configuration files so that the previously published experiments are easy to reproduce.",
}
@inproceedings{dou-etal-2015-unifying,
    title = "Unifying {B}ayesian Inference and Vector Space Models for Improved Decipherment",
    author = "Dou, Qing  and
      Vaswani, Ashish  and
      Knight, Kevin  and
      Dyer, Chris",
    booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = jul,
    year = "2015",
    address = "Beijing, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P15-1081",
    doi = "10.3115/v1/P15-1081",
    pages = "836--845",
    abstract = "We introduce into Bayesian decipherment a base distribution derived from similarities of word embeddings. We use Dirichlet multinomial regression (Mimno and McCallum, 2012) to learn a mapping between ciphertext and plaintext word embeddings from non-parallel data. Experimental results show that the base distribution is highly beneficial to decipherment, improving state-of-the-art decipherment accuracy from 45.8% to 67.4% for Spanish/English, and from 5.1% to 11.2% for Malagasy/English.",
}
@inproceedings{nuhn-ney-2014-em,
    title = "{EM} Decipherment for Large Vocabularies",
    author = "Nuhn, Malte  and
      Ney, Hermann",
    booktitle = "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jun,
    year = "2014",
    address = "Baltimore, Maryland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P14-2123",
    doi = "10.3115/v1/P14-2123",
    pages = "759--764",
    abstract = "This paper addresses the problem of EM-based decipherment for large vocabularies. Here, decipherment is essentially a tagging problem: Every cipher token is tagged with some plaintext type. As with other tagging problems, this one can be treated as a Hidden Markov Model (HMM), only here, the vocabularies are large, so the usual O(NV 2 ) exact EM approach is infeasible. When faced with this situation, many people turn to sampling. However, we propose to use a type of approximate EM and show that it works well. The basic idea is to collect fractional counts only over a small subset of links in the forward-backward lattice. The subset is different for each iteration of EM. One option is to use beam search to do the subsetting. The second method restricts the successor words that are looked at, for each hypothesis. It does this by consulting pre-computed tables of likely n-grams and likely substitutions.",
}
@inproceedings{dou-etal-2014-beyond,
    title = "Beyond Parallel Data: Joint Word Alignment and Decipherment Improves Machine Translation",
    author = "Dou, Qing  and
      Vaswani, Ashish  and
      Knight, Kevin",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1061",
    doi = "10.3115/v1/D14-1061",
    pages = "557--565",
    abstract = "Inspired by previous work, where decipherment is used to improve machine translation, we propose a new idea to combine word alignment and decipherment into a single learning process. We use EM to estimate the model parameters, not only to maximize the probability of parallel corpus, but also the monolingual corpus. We apply our approach to improve Malagasy-English machine translation, where only a small amount of parallel data is available. In our experiments, we observe gains of 0.9 to 2.1 Bleu over a strong baseline.",
}
@inproceedings{nuhn-etal-2014-improved,
    title = "Improved Decipherment of Homophonic Ciphers",
    author = "Nuhn, Malte  and
      Schamper, Julian  and
      Ney, Hermann",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1184",
    doi = "10.3115/v1/D14-1184",
    pages = "1764--1768",
    abstract = "In this paper, we present two improvements to the beam search approach for solving homophonic substitution ciphers presented in Nuhn et al. (2013): An improved rest cost estimation together with an optimized strategy for obtaining the order in which the symbols of the cipher are deciphered reduces the beam size needed to successfully decipher the Zodiac-408 cipher from several million down to less than one hundred: The search effort is reduced from several hours of computation time to just a few seconds on a single CPU. These improvements allow us to successfully decipher the second part of the famous Beale cipher (see (Ward et al., 1885) and e.g. (King, 1993)): Having 182 different cipher symbols while having a length of just 762 symbols, the decipherment is way more challenging than the decipherment of the previously deciphered Zodiac408 cipher (length 408, 54 different symbols). To the best of our knowledge, this cipher has not been deciphered automatically before.",
}
@inproceedings{nuhn-knight-2014-cipher,
    title = "Cipher Type Detection",
    author = "Nuhn, Malte  and
      Knight, Kevin",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1185",
    doi = "10.3115/v1/D14-1185",
    pages = "1769--1773",
    abstract = "Manual analysis and decryption of enciphered documents is a tedious and error prone work. Often—even after spending large amounts of time on a particular cipher—no decipherment can be found. Automating the decryption of various types of ciphers makes it possible to sift through the large number of encrypted messages found in libraries and archives, and to focus human effort only on a small but potentially interesting subset of them. In this work, we train a classifier that is able to predict which encipherment method has been used to generate a given ciphertext. We are able to distinguish 50 different cipher types (specified by the American Cryptogram Association) with an accuracy of 58.5%. This is a 11.2% absolute improvement over the best previously published classifier.",
}
@inproceedings{hauer-etal-2014-solving,
    title = "Solving Substitution Ciphers with Combined Language Models",
    author = "Hauer, Bradley  and
      Hayward, Ryan  and
      Kondrak, Grzegorz",
    booktitle = "Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",
    month = aug,
    year = "2014",
    address = "Dublin, Ireland",
    publisher = "Dublin City University and Association for Computational Linguistics",
    url = "https://aclanthology.org/C14-1218",
    pages = "2314--2325",
    abstract = "We propose a novel approach to deciphering short monoalphabetic ciphers that combines both character-level and word-level language models. We formulate decipherment as tree search, and use Monte Carlo Tree Search (MCTS) as a fast alternative to beam search. Our experiments show a significant improvement over the state of the art on a benchmark suite of short ciphers. Our approach can also handle ciphers without spaces and ciphers with noise, which allows us to explore its applications to unsupervised transliteration and deniable encryption.",
}
@inproceedings{knight-2013-decipherment,
    title = "Decipherment",
    author = "Knight, Kevin",
    booktitle = "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Tutorials)",
    month = aug,
    year = "2013",
    address = "Sofia, Bulgaria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P13-5003",
    pages = "3--4",
    abstract = "The first natural language processing systems had a straightforward goal: decipher coded messages sent by the enemy. This tutorial explores connections between early decipherment research and today’s NLP work. We cover classic military and diplomatic ciphers, automatic decipherment algorithms, unsolved ciphers, language translation as decipherment, and analyzing ancient writing as decipherment.",
}
@inproceedings{ravi-2013-scalable,
    title = "Scalable Decipherment for Machine Translation via Hash Sampling",
    author = "Ravi, Sujith",
    booktitle = "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2013",
    address = "Sofia, Bulgaria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P13-1036",
    pages = "362--371",
    abstract = "In this paper, we propose a new Bayesian inference method to train statistical machine translation systems using only nonparallel corpora. Following a probabilistic decipherment approach, we first introduce a new framework for decipherment training that is flexible enough to incorporate any number/type of features (besides simple bag-of-words) as side-information used for estimating translation models. In order to perform fast, efficient Bayesian inference in this framework, we then derive a hash sampling strategy that is inspired by the work of Ahmed et al. (2012). The new translation hash sampler enables us to scale elegantly to complex models (for the first time) and large vocabulary/corpora sizes. We show empirical results on the OPUS data—our method yields the best BLEU scores compared to existing approaches, while achieving significant computational speedups (several orders faster). We also report for the first time—BLEU score results for a largescale MT task using only non-parallel data (EMEA corpus).",
}
@inproceedings{nuhn-ney-2013-decipherment,
    title = "Decipherment Complexity in 1:1 Substitution Ciphers",
    author = "Nuhn, Malte  and
      Ney, Hermann",
    booktitle = "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2013",
    address = "Sofia, Bulgaria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P13-1060",
    pages = "615--621",
    abstract = "In this paper we show that even for the case of 1:1 substitution ciphers—which encipher plaintext symbols by exchanging them with a unique substitute—finding the optimal decipherment with respect to a bigram language model is NP-hard. We show that in this case the decipherment problem is equivalent to the quadratic assignment problem (QAP). To the best of our knowledge, this connection between the QAP and the decipherment problem has not been known in the literature before.",
}
@inproceedings{nuhn-etal-2013-beam,
    title = "Beam Search for Solving Substitution Ciphers",
    author = "Nuhn, Malte  and
      Schamper, Julian  and
      Ney, Hermann",
    booktitle = "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2013",
    address = "Sofia, Bulgaria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P13-1154",
    pages = "1568--1576",
    abstract = "In this paper we address the problem of solving substitution ciphers using a beam search approach. We present a conceptually consistent and easy to implement method that improves the current state of the art for decipherment of substitution ciphers and is able to use high order n-gram language models. We show experiments with 1:1 substitution ciphers in which the guaranteed optimal solution for 3-gram language models has 38.6% decipherment error, while our approach achieves 4.13% decipherment error in a fraction of time by using a 6-gram language model. We also apply our approach to the famous Zodiac-408 cipher and obtain slightly better (and near to optimal) results than previously published. Unlike the previous state-of-the-art approach that uses additional word lists to evaluate possible decipherments, our approach only uses a letterbased 6-gram language model. Furthermore we use our algorithm to solve large vocabulary substitution ciphers and improve the best published decipherment error rate based on the Gigaword corpus of 7.8% to 6.0% error rate.",
}
@inproceedings{berg-kirkpatrick-klein-2013-decipherment,
    title = "Decipherment with a Million Random Restarts",
    author = "Berg-Kirkpatrick, Taylor  and
      Klein, Dan",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D13-1087",
    pages = "874--878",
    abstract = "This paper investigates the utility and effect of running numerous random restarts when using EM to attack decipherment problems. We find that simple decipherment models are able to crack homophonic substitution ciphers with high accuracy if a large number of random restarts are used but almost completely fail with only a few random restarts. For particularly difficult homophonic ciphers, we find that big gains in accuracy are to be had by running upwards of 100K random restarts, which we accomplish efficiently using a GPU-based parallel implementation. We run a series of experiments using millions of random restarts in order to investigate other empirical properties of decipherment problems, including the famously uncracked Zodiac 340.",
}
@inproceedings{dou-knight-2013-dependency,
    title = "Dependency-Based Decipherment for Resource-Limited Machine Translation",
    author = "Dou, Qing  and
      Knight, Kevin",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D13-1173",
    pages = "1668--1676",
    abstract = "We introduce dependency relations into deciphering foreign languages and show that dependency relations help improve the state-ofthe-art deciphering accuracy by over 500%. We learn a translation lexicon from large amounts of genuinely non parallel data with decipherment to improve a phrase-based machine translation system trained with limited parallel data. In experiments, we observe BLEU gains of 1.2 to 1.8 across three different test sets.",
}
@inproceedings{reddy-knight-2012-decoding,
    title = "Decoding Running Key Ciphers",
    author = "Reddy, Sravana  and
      Knight, Kevin",
    booktitle = "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2012",
    address = "Jeju Island, Korea",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P12-2016",
    pages = "80--84",
    abstract = "There has been recent interest in the problem of decoding letter substitution ciphers using techniques inspired by natural language processing. We consider a different type of classical encoding scheme known as the running key cipher, and propose a search solution using Gibbs sampling with a word language model. We evaluate our method on synthetic ciphertexts of different lengths, and find that it outperforms previous work that employs Viterbi decoding with character-based models.",
}
@inproceedings{nuhn-etal-2012-deciphering,
    title = "Deciphering Foreign Language by Combining Language Models and Context Vectors",
    author = "Nuhn, Malte  and
      Mauser, Arne  and
      Ney, Hermann",
    booktitle = "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2012",
    address = "Jeju Island, Korea",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P12-1017",
    pages = "156--164",
    abstract = "In this paper we show how to train statistical machine translation systems on reallife tasks using only non-parallel monolingual data from two languages. We present a modification of the method shown in (Ravi and Knight, 2011) that is scalable to vocabulary sizes of several thousand words. On the task shown in (Ravi and Knight, 2011) we obtain better results with only 5% of the computational effort when running our method with an n-gram language model. The efficiency improvement of our method allows us to run experiments with vocabulary sizes of around 5,000 words, such as a non-parallel version of the VERBMOBIL corpus. We also report results using data from the monolingual French and English GIGAWORD corpora.",
}
@inproceedings{dou-knight-2012-large,
    title = "Large Scale Decipherment for Out-of-Domain Machine Translation",
    author = "Dou, Qing  and
      Knight, Kevin",
    booktitle = "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning",
    month = jul,
    year = "2012",
    address = "Jeju Island, Korea",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D12-1025",
    pages = "266--275",
    abstract = "We apply slice sampling to Bayesian decipherment and use our new decipherment framework to improve out-of-domain machine translation. Compared with the state of the art algorithm, our approach is highly scalable and produces better results, which allows us to decipher ciphertext with billions of tokens and hundreds of thousands of word types with high accuracy. We decipher a large amount of monolingual data to improve out-of-domain translation and achieve significant gains of up to 3.8 BLEU points.",
}
@inproceedings{knight-etal-2011-copiale,
    title = "The Copiale Cipher",
    author = "Knight, Kevin  and
      Megyesi, Be{\'a}ta  and
      Schaefer, Christiane",
    booktitle = "Proceedings of the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web",
    month = jun,
    year = "2011",
    address = "Portland, Oregon",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W11-1202",
    pages = "2--9",
    abstract = "The Copiale cipher is a 105-page enciphered book dated 1866. We describe the features of the book and the method by which we deciphered it.",
}
@inproceedings{ravi-knight-2011-deciphering,
    title = "Deciphering Foreign Language",
    author = "Ravi, Sujith  and
      Knight, Kevin",
    booktitle = "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2011",
    address = "Portland, Oregon, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P11-1002",
    pages = "12--21",
    abstract = "In this work, we tackle the task of machine translation (MT) without parallel training data. We frame the MT problem as a decipherment task, treating the foreign text as a cipher for English and present novel methods for training translation models from nonparallel text.",
}
@inproceedings{ravi-knight-2011-bayesian,
    title = "{B}ayesian Inference for Zodiac and Other Homophonic Ciphers",
    author = "Ravi, Sujith  and
      Knight, Kevin",
    booktitle = "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2011",
    address = "Portland, Oregon, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P11-1025",
    pages = "239--247",
    abstract = "We introduce a novel Bayesian approach for deciphering complex substitution ciphers. Our method uses a decipherment model which combines information from letter n-gram language models as well as word dictionaries. Bayesian inference is performed on our model using an efficient sampling technique. We evaluate the quality of the Bayesian decipherment output on simple and homophonic letter substitution ciphers and show that unlike a previous approach, our method consistently produces almost 100% accurate decipherments. The new method can be applied on more complex substitution ciphers and we demonstrate its utility by cracking the famous Zodiac-408 cipher in a fully automated fashion, which has never been done before.",
}
@inproceedings{berg-kirkpatrick-klein-2011-simple,
    title = "Simple Effective Decipherment via Combinatorial Optimization",
    author = "Berg-Kirkpatrick, Taylor  and
      Klein, Dan",
    booktitle = "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing",
    month = jul,
    year = "2011",
    address = "Edinburgh, Scotland, UK.",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D11-1029",
    pages = "313--321",
    abstract = "We present a simple objective function that when optimized yields accurate solutions to both decipherment and cognate pair identification problems. The objective simultaneously scores a matching between two alphabets and a matching between two lexicons, each in a different language. We introduce a simple coordinate descent procedure that efficiently finds effective solutions to the resulting combinatorial optimization problem. Our system requires only a list of words in both languages as input, yet it competes with and surpasses several state-of-the-art systems that are both substantially more complex and make use of more information.",
}
@inproceedings{corlett-penn-2010-exact,
    title = "An Exact {A}* Method for Deciphering Letter-Substitution Ciphers",
    author = "Corlett, Eric  and
      Penn, Gerald",
    booktitle = "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2010",
    address = "Uppsala, Sweden",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P10-1106",
    pages = "1040--1047",
    abstract = "Letter-substitution ciphers encode a document from a known or hypothesized language into an unknown writing system or an unknown encoding of a known writing system. It is a problem that can occur in a number of practical applications, such as in the problem of determining the encodings of electronic documents in which the language is known, but the encoding standard is not. It has also been used in relation to OCR applications. In this paper, we introduce an exact method for deciphering messages using a generalization of the Viterbi algorithm. We test this model on a set of ciphers developed from various web sites, and find that our algorithm has the potential to be a viable, practical method for efficiently solving decipherment problems.",
}
@inproceedings{snyder-etal-2010-statistical,
    title = "A Statistical Model for Lost Language Decipherment",
    author = "Snyder, Benjamin  and
      Barzilay, Regina  and
      Knight, Kevin",
    booktitle = "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2010",
    address = "Uppsala, Sweden",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P10-1107",
    pages = "1048--1057",
    abstract = "In this paper we propose a method for the automatic decipherment of lost languages. Given a non-parallel corpus in a known related language, our model produces both alphabetic mappings and translations of words into their corresponding cognates. We employ a non-parametric Bayesian framework to simultaneously capture both low-level character mappings and highlevel morphemic correspondences. This formulation enables us to encode some of the linguistic intuitions that have guided human decipherers. When applied to the ancient Semitic language Ugaritic, the model correctly maps 29 of 30 letters to their Hebrew counterparts, and deduces the correct Hebrew cognate for 60% of the Ugaritic words which have cognates in Hebrew.",
}
@inproceedings{sinha-etal-2009-network,
    title = "Network analysis reveals structure indicative of syntax in the corpus of undeciphered Indus civilization inscriptions",
    author = "Sinha, Sitabhra  and
      Pan, Raj Kumar  and
      Yadav, Nisha  and
      Vahia, Mayank  and
      Mahadevan, Iravatham",
    booktitle = "Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing ({T}ext{G}raphs-4)",
    month = aug,
    year = "2009",
    address = "Suntec, Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W09-3202",
    pages = "5--13",
    abstract = "Archaeological excavations in the sites of the Indus Valley civilization (2500-1900 BCE) in Pakistan and northwestern India have unearthed a large number of artifacts with inscriptions made up of hundreds of distinct signs. To date, there is no generally accepted decipherment of these sign sequences, and there have been suggestions that the signs could be non-linguistic. Here we apply complex network analysis techniques on the database of available Indus inscriptions, with the aim of detecting patterns indicative of syntactic structure in this sign system. Our results show the presence of regularities, e.g., in the segmentation trees of the sequences, that suggest the existence of a grammar underlying the construction of the sequences.",
}
@inproceedings{knight-sproat-2009-writing,
    title = "Writing Systems, Transliteration and Decipherment",
    author = "Knight, Kevin  and
      Sproat, Richard",
    booktitle = "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Tutorial Abstracts",
    month = may,
    year = "2009",
    address = "Boulder, Colorado",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N09-4008",
    pages = "15--16",
}
@inproceedings{ravi-knight-2008-attacking,
    title = "Attacking Decipherment Problems Optimally with Low-Order {N}-gram Models",
    author = "Ravi, Sujith  and
      Knight, Kevin",
    booktitle = "Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2008",
    address = "Honolulu, Hawaii",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D08-1085",
    pages = "812--819",
    abstract = "We introduce a method for solving substitution ciphers using low-order letter n-gram models. This method enforces global constraints using integer programming, and it guarantees that no decipherment key is overlooked. We carry out extensive empirical experiments showing how decipherment accuracy varies as a function of cipher length and n-gram order. We also make an empirical investigation of Shannon’s (1949) theory of uncertainty in decipherment.",
}
@inproceedings{knight-etal-2006-unsupervised,
    title = "Unsupervised Analysis for Decipherment Problems",
    author = "Knight, Kevin  and
      Nair, Anish  and
      Rathod, Nishit  and
      Yamada, Kenji",
    booktitle = "Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions",
    month = jul,
    year = "2006",
    address = "Sydney, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P06-2065",
    pages = "499--506",
    abstract = "We study a number of natural language decipherment problems using unsupervised learning. These include letter substitution ciphers, character code conversion, phonetic decipherment, and word-based ciphers with relevance to machine translation. Straightforward unsupervised learning techniques most often fail on the first try, so we describe techniques for understanding errors and significantly increasing performance.",
}
@inproceedings{knight-yamada-1999-computational,
    title = "A Computational Approach to Deciphering Unknown Scripts",
    author = "Knight, Kevin  and
      Yamada, Kenji",
    booktitle = "Unsupervised Learning in Natural Language Processing",
    year = "1999",
    url = "https://aclanthology.org/W99-0906",
    abstract = "We propose and evaluate computational techniques for deciphering unknown scripts. We focus on the case in which an unfamiliar script encodes a known language. The decipherment of a brief document or inscription is driven by data about the spoken language. We consider which scripts are easy or hard to decipher, how much data is required, and whether the techniques are robust against language change over time.",
}
@inproceedings{sukhotin-1988-optimization,
    title = "Optimization Algorithms of Deciphering as the Elements of a Linguistic Theory",
    author = "Sukhotin, B. V.",
    booktitle = "{C}oling {B}udapest 1988 Volume 2: {I}nternational {C}onference on {C}omputational {L}inguistics",
    year = "1988",
    url = "https://aclanthology.org/C88-2134",
}
@inproceedings{sukhotin-1973-deciphering,
    title = "Deciphering Methods as a Means of Linguistic Research",
    author = "Sukhotin, B. V.",
    booktitle = "{COLING} 1973 Volume 1: Computational And Mathematical Linguistics: Proceedings of the International Conference on Computational Linguistics",
    year = "1973",
    url = "https://aclanthology.org/C73-1017",
}
@article{Jakobsen1995AFM,
  title={A Fast Method for Cryptanalysis of Substitution Ciphers},
  author={Thomas P. Jakobsen},
  journal={Cryptologia},
  year={1995},
  volume={19},
  pages={265-274}
}

@inproceedings{Kopal2019CryptanalysisOH,
  title={Cryptanalysis of Homophonic Substitution Ciphers Using Simulated Annealing with Fixed Temperature},
  author={Nils Kopal},
  booktitle={International Conference on Historical Cryptology},
  year={2019},
  url={https://www.ep.liu.se/ecp/158/012/ecp19158012.pdf},
}

@article{Dhavare2013EfficientCO,
  title={Efficient Cryptanalysis of Homophonic Substitution Ciphers},
  author={Amrapali Dhavare and Richard M. Low and Mark Stamp},
  journal={Cryptologia},
  year={2013},
  volume={37},
  pages={250 - 281},
  url={http://www.cs.sjsu.edu/faculty/stamp/RUA/homophonic.pdf},
}

@inproceedings{berg-kirkpatrick-klein-2013-decipherment,
    title = "Decipherment with a Million Random Restarts",
    author = "Berg-Kirkpatrick, Taylor  and
      Klein, Dan",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D13-1087",
    pages = "874--878",
}

@inproceedings{kambhatla-etal-2018-decipherment,
    title = "Decipherment of Substitution Ciphers with Neural Language Models",
    author = "Kambhatla, Nishant  and
      Mansouri Bigvand, Anahita  and
      Sarkar, Anoop",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1102",
    doi = "10.18653/v1/D18-1102",
    pages = "869--874",
    abstract = "Decipherment of homophonic substitution ciphers using language models is a well-studied task in NLP. Previous work in this topic scores short local spans of possible plaintext decipherments using n-gram language models. The most widely used technique is the use of beam search with n-gram language models proposed by Nuhn et al.(2013). We propose a beam search algorithm that scores the entire candidate plaintext at each step of the decipherment using a neural language model. We augment beam search with a novel rest cost estimation that exploits the prediction power of a neural language model. We compare against the state of the art n-gram based methods on many different decipherment tasks. On challenging ciphers such as the Beale cipher we provide significantly better error rates with much smaller beam sizes.",
}

@inproceedings{nuhn-etal-2012-deciphering,
    title = "Deciphering Foreign Language by Combining Language Models and Context Vectors",
    author = "Nuhn, Malte  and
      Mauser, Arne  and
      Ney, Hermann",
    booktitle = "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2012",
    address = "Jeju Island, Korea",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P12-1017",
    pages = "156--164",
}

@inproceedings{nuhn-ney-2014-em,
    title = "{EM} Decipherment for Large Vocabularies",
    author = "Nuhn, Malte  and
      Ney, Hermann",
    booktitle = "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jun,
    year = "2014",
    address = "Baltimore, Maryland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P14-2123",
    doi = "10.3115/v1/P14-2123",
    pages = "759--764",
}

@inproceedings{nuhn-etal-2014-improved,
    title = "Improved Decipherment of Homophonic Ciphers",
    author = "Nuhn, Malte  and
      Schamper, Julian  and
      Ney, Hermann",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1184",
    doi = "10.3115/v1/D14-1184",
    pages = "1764--1768",
}

@inproceedings{nuhn-etal-2013-beam,
    title = "Beam Search for Solving Substitution Ciphers",
    author = "Nuhn, Malte  and
      Schamper, Julian  and
      Ney, Hermann",
    booktitle = "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2013",
    address = "Sofia, Bulgaria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P13-1154",
    pages = "1568--1576",
}

@inproceedings{nuhn-etal-2015-unravel,
    title = "{UNRAVEL}{---}{A} Decipherment Toolkit",
    author = "Nuhn, Malte  and
      Schamper, Julian  and
      Ney, Hermann",
    booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
    month = jul,
    year = "2015",
    address = "Beijing, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P15-2090",
    doi = "10.3115/v1/P15-2090",
    pages = "549--553",
}

@inproceedings{chu-etal-2020-solving,
    title = "{S}olving {H}istorical {D}ictionary {C}odes with a {N}eural {L}anguage {M}odel",
    author = "Chu, Christopher  and
      Valenti, Raphael  and
      Knight, Kevin",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.471",
    doi = "10.18653/v1/2020.emnlp-main.471",
    pages = "5845--5854",
    abstract = "We solve difficult word-based substitution codes by constructing a decoding lattice and searching that lattice with a neural language model. We apply our method to a set of enciphered letters exchanged between US Army General James Wilkinson and agents of the Spanish Crown in the late 1700s and early 1800s, obtained from the US Library of Congress. We are able to decipher 75.1{\%} of the cipher-word tokens correctly.",
}
@inproceedings{oh-etal-2021-surprisal,
    title = "Surprisal Estimators for Human Reading Times Need Character Models",
    author = "Oh, Byung-Doh  and
      Clark, Christian  and
      Schuler, William",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.290",
    doi = "10.18653/v1/2021.acl-long.290",
    pages = "3746--3757",
    abstract = "While the use of character models has been popular in NLP applications, it has not been explored much in the context of psycholinguistic modeling. This paper presents a character model that can be applied to a structural parser-based processing model to calculate word generation probabilities. Experimental results show that surprisal estimates from a structural processing model using this character model deliver substantially better fits to self-paced reading, eye-tracking, and fMRI data than those from large-scale language models trained on much more data. This may suggest that the proposed processing model provides a more humanlike account of sentence processing, which assumes a larger role of morphology, phonotactics, and orthographic complexity than was previously thought.",
}

@inproceedings{boldsen-etal-2022-interpreting,
    title = "Interpreting Character Embeddings With Perceptual Representations: The Case of Shape, Sound, and Color",
    author = "Boldsen, Sidsel  and
      Agirrezabal, Manex  and
      Hollenstein, Nora",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.470",
    doi = "10.18653/v1/2022.acl-long.470",
    pages = "6819--6836",
    abstract = "Character-level information is included in many NLP models, but evaluating the information encoded in character representations is an open issue. We leverage perceptual representations in the form of shape, sound, and color embeddings and perform a representational similarity analysis to evaluate their correlation with textual representations in five languages. This cross-lingual analysis shows that textual character representations correlate strongly with sound representations for languages using an alphabetic script, while shape correlates with featural scripts.We further develop a set of probing classifiers to intrinsically evaluate what phonological information is encoded in character embeddings. Our results suggest that information on features such as voicing are embedded in both LSTM and transformer-based representations.",
}

@inproceedings{alvarez-melis-jaakkola-2018-gromov,
    title = "Gromov-Wasserstein Alignment of Word Embedding Spaces",
    author = "Alvarez-Melis, David  and
      Jaakkola, Tommi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1214",
    doi = "10.18653/v1/D18-1214",
    pages = "1881--1890",
    abstract = "Cross-lingual or cross-domain correspondences play key roles in tasks ranging from machine translation to transfer learning. Recently, purely unsupervised methods operating on monolingual embeddings have become effective alignment tools. Current state-of-the-art methods, however, involve multiple steps, including heuristic post-hoc refinement strategies. In this paper, we cast the correspondence problem directly as an optimal transport (OT) problem, building on the idea that word embeddings arise from metric recovery algorithms. Indeed, we exploit the Gromov-Wasserstein distance that measures how similarities between pairs of words relate across languages. We show that our OT objective can be estimated efficiently, requires little or no tuning, and results in performance comparable with the state-of-the-art in various unsupervised word translation tasks.",
}

@mastersthesis{Deanne2021,
  author = {Charan, Deanne},
  title = {Generative Adversarial Networks for Classic Cryptanalysis},
  year = {2021},
  url = {https://scholarworks.sjsu.edu/etd_projects/1034/}
}

@inproceedings{Stamp2018HiddenMM,
  title={Hidden Markov Models for Vigen{\`e}re Cryptanalysis},
  author={Mark Stamp and Fabio Di Troia and Miles Stamp and Jasper Huang},
  booktitle={International Conference on Historical Cryptology},
  url={https://www.semanticscholar.org/paper/Hidden-Markov-Models-for-Vigen%C3%A8re-Cryptanalysis-Stamp-Troia/0fab7fabe5d3cf30ee615ca81e30d2ee3d45c295},
  year={2018}
}

@article{Hallman2022PosterEU,
  title={Poster EveGAN: Using Generative Deep Learning for Cryptanalysis},
  author={Roger A. Hallman},
  journal={Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security},
  year={2022},
  url={https://www.semanticscholar.org/paper/Poster-EveGAN%3A-Using-Generative-Deep-Learning-for-Hallman/3e23dc5a5b4f8d0a888d201c1c59b1264945de20},
}

@inproceedings{Focardi2018NeuralCO,
  title={Neural Cryptanalysis of Classical Ciphers},
  author={Riccardo Focardi and Flaminia L. Luccio},
  booktitle={Italian Conference on Theoretical Computer Science},
  year={2018},
  url={https://www.semanticscholar.org/paper/Neural-Cryptanalysis-of-Classical-Ciphers-Focardi-Luccio/3768eacda976709580251a6d1de228393d974335}
}

@article{Gomez2018UnsupervisedCC,
  title={Unsupervised Cipher Cracking Using Discrete GANs},
  author={Aidan N. Gomez and Sicong Huang and Ivan Zhang and Bryan M. Li and Muhammad Osama and Lukasz Kaiser},
  journal={ArXiv},
  year={2018},
  volume={abs/1801.04883},
  url={https://www.semanticscholar.org/paper/Unsupervised-Cipher-Cracking-Using-Discrete-GANs-Gomez-Huang/b589b9f10258efb5404f06693c659d68e67929d3}
}

@inproceedings{gambardella-etal-2022-identifying,
    title = "Identifying Cleartext in Historical Ciphers",
    author = "Gambardella, Maria-Elena  and
      Megyesi, Beata  and
      Pettersson, Eva",
    booktitle = "Proceedings of the Second Workshop on Language Technologies for Historical and Ancient Languages",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lt4hala-1.1",
    pages = "1--9",
    abstract = "In historical encrypted sources we can find encrypted text sequences, also called ciphertext, as well as non-encrypted cleartexts written in a known language. While most of the cryptanalysis focuses on the decryption of ciphertext, cleartext is often overlooked although it can give us important clues about the historical interpretation and contextualisation of the manuscript. In this paper, we investigate to what extent we can automatically distinguish cleartext from ciphertext in historical ciphers and to what extent we are able to identify its language. The problem is challenging as cleartext sequences in ciphers are often short, up to a few words, in different languages due to historical code-switching. To identify the sequences and the language(s), we chose a rule-based approach and run 7 different models using historical language models on various ciphertexts.",
}

@article{10.2307/25678614,
 ISSN = {10724117, 19476213},
 URL = {http://www.jstor.org/stable/25678614},
 author = {Sarah Spence Adams},
 journal = {Math Horizons},
 number = {4},
 pages = {5--7},
 publisher = {Mathematical Association of America},
 title = {Historical Ciphers and Ancient Languages},
 urldate = {2023-01-26},
 volume = {13},
 year = {2006}
}

@misc{https://doi.org/10.48550/arxiv.2103.10360,
  doi = {10.48550/ARXIV.2103.10360},
  
  url = {https://arxiv.org/abs/2103.10360},
  
  author = {Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie},
  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {GLM: General Language Model Pretraining with Autoregressive Blank Infilling},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{https://doi.org/10.48550/arxiv.2202.11705,
  doi = {10.48550/ARXIV.2202.11705},
  
  url = {https://arxiv.org/abs/2202.11705},
  
  author = {Qin, Lianhui and Welleck, Sean and Khashabi, Daniel and Choi, Yejin},
  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {COLD Decoding: Energy-based Constrained Text Generation with Langevin Dynamics},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{https://doi.org/10.48550/arxiv.2109.06157,
  doi = {10.48550/ARXIV.2109.06157},
  
  url = {https://arxiv.org/abs/2109.06157},
  
  author = {Zhang, Michael J. Q. and Choi, Eunsol},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {SituatedQA: Incorporating Extra-Linguistic Contexts into QA},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}


@misc{https://doi.org/10.48550/arxiv.2210.13701,
  doi = {10.48550/ARXIV.2210.13701},
  
  url = {https://arxiv.org/abs/2210.13701},
  
  author = {Chen, Hung-Ting and Zhang, Michael J. Q. and Choi, Eunsol},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Rich Knowledge Sources Bring Complex Knowledge Conflicts: Recalibrating Models to Reflect Conflicting Evidence},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{https://doi.org/10.48550/arxiv.2102.09690,
  doi = {10.48550/ARXIV.2102.09690},
  
  url = {https://arxiv.org/abs/2102.09690},
  
  author = {Zhao, Tony Z. and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Calibrate Before Use: Improving Few-Shot Performance of Language Models},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@inproceedings{wallace-etal-2022-automated,
    title = "Automated Crossword Solving",
    author = "Wallace, Eric  and
      Tomlin, Nicholas  and
      Xu, Albert  and
      Yang, Kevin  and
      Pathak, Eshaan  and
      Ginsberg, Matthew  and
      Klein, Dan",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.219",
    doi = "10.18653/v1/2022.acl-long.219",
    pages = "3073--3085",
    abstract = "We present the Berkeley Crossword Solver, a state-of-the-art approach for automatically solving crossword puzzles. Our system works by generating answer candidates for each crossword clue using neural question answering models and then combines loopy belief propagation with local search to find full puzzle solutions. Compared to existing approaches, our system improves exact puzzle accuracy from 57{\%} to 82{\%} on crosswords from The New York Times and obtains 99.9{\%} letter accuracy on themeless puzzles. Our system also won first place at the top human crossword tournament, which marks the first time that a computer program has surpassed human performance at this event. To facilitate research on question answering and crossword solving, we analyze our system{'}s remaining errors and release a dataset of over six million question-answer pairs.",
}
@inproceedings{Knight1999ACA,
  title={A Computational Approach to Deciphering Unknown Scripts},
  author={Kevin Knight and Kenji Yamada},
  year={1999},
  url={https://aclanthology.org/W99-0906.pdf},
}
@inproceedings{Knight2011TheCC,
  title={The Copiale Cipher},
  author={Kevin Knight and Be{\'a}ta Megyesi and Christiane Schaefer},
  booktitle={BUCC@ACL},
  year={2011},
  url={https://aclanthology.org/W11-1202.pdf},
}

@inproceedings{Ravi2011BayesianIF,
  title={Bayesian Inference for Zodiac and Other Homophonic Ciphers},
  author={Sujith Ravi and Kevin Knight},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2011},
  url={https://aclanthology.org/P11-1025.pdf},
}

@inproceedings{Ravi2011DecipheringFL,
  title={Deciphering Foreign Language},
  author={Sujith Ravi and Kevin Knight},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2011},
  url={https://aclanthology.org/P11-1002.pdf},
}

@inproceedings{Knight2012TheSO,
  title={The Secrets of the Copiale Cipher},
  author={Kevin Knight and Be{\'a}ta Megyesi and Christiane Schaefer},
  year={2012},
  url={https://journal.equinoxpub.com/JRFF/article/view/7999},
}

@inproceedings{Reddy2012DecodingRK,
  title={Decoding Running Key Ciphers},
  author={Sravana Reddy and Kevin Knight},
  booktitle={ACL},
  year={2012},
  url={https://aclanthology.org/P12-2016.pdf},
}

@inproceedings{Dou2012LargeSD,
  title={Large Scale Decipherment for Out-of-Domain Machine Translation},
  author={Qing Dou and Kevin Knight},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2012},
  url={https://www.aclweb.org/anthology/D12-1025.pdf},
}

@inproceedings{Dou2013DependencyBasedDF,
  title={Dependency-Based Decipherment for Resource-Limited Machine Translation},
  author={Qing Dou and Kevin Knight},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2013},
  url={https://www.aclweb.org/anthology/D13-1173.pdf},
}

@mastersthesis{Hauer2016ComputationalDO,
  title={Computational Decipherment of Unknown Scripts},
  author={Bradley Hauer},
  year={2016},
  url={https://era.library.ualberta.ca/items/1ff57e8b-825a-40bb-b1b6-941c76f97a3f},
}

@phdthesis{Nuhn2019UnsupervisedTW,
  title={Unsupervised training with applications in natural language processing},
  author={Malte Nuhn},
  year={2019},
  url={http://publications.rwth-aachen.de/record/772331/files/772331.pdf}
}

@inproceedings{Leierzopf2021AMM,
  title={A Massive Machine-Learning Approach For Classical Cipher Type Detection Using Feature Engineering},
  author={Ernst Leierzopf and Nils Kopal and Bernhard Esslinger and Harald Lampesberger and Eckehard Hermann},
  booktitle={International Conference on Historical Cryptology},
  year={2021},
  url={https://ecp.ep.liu.se/index.php/histocrypt/article/view/164}
}

@inproceedings{Dou2014BeyondPD,
  title={Beyond Parallel Data: Joint Word Alignment and Decipherment Improves Machine Translation},
  author={Qing Dou and Ashish Vaswani and Kevin Knight},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  url = {https://aclanthology.org/D14-1061.pdf},
  year={2014}
}

@inproceedings{Dou2015UnifyingBI,
  title={Unifying Bayesian Inference and Vector Space Models for Improved Decipherment},
  author={Qing Dou and Ashish Vaswani and Kevin Knight and Chris Dyer},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  url = {http://anthology.aclweb.org/P/P15/P15-1081.pdf},
  year={2015}
}

@inproceedings{pourdamghani-knight-2017-deciphering,
    title = "Deciphering Related Languages",
    author = "Pourdamghani, Nima  and
      Knight, Kevin",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1266",
    doi = "10.18653/v1/D17-1266",
    pages = "2513--2518",
    abstract = "We present a method for translating texts between close language pairs. The method does not require parallel data, and it does not require the languages to be written in the same script. We show results for six language pairs: Afrikaans/Dutch, Bosnian/Serbian, Danish/Swedish, Macedonian/Bulgarian, Malaysian/Indonesian, and Polish/Belorussian. We report BLEU scores showing our method to outperform others that do not use parallel data.",
}

@article{Yin2018DeciphermentOH,
  title={Decipherment of Historical Manuscript Images},
  author={Xusen Yin and Nada Aldarrab and Be{\'a}ta Megyesi and Kevin Knight},
  journal={2019 International Conference on Document Analysis and Recognition (ICDAR)},
  url = {https://arxiv.org/abs/1810.04297},
  year={2018},
  pages={78-85}
}

@mastersthesis{aldarrab_thesis_decipherment,
  url = {https://digitallibrary.usc.edu/Share/61b761151l1kvxj4434b7d1pqovm044r},  
  author = {Nada Aldarrab},  
  title = {Automatic decipherment of historical manuscripts},
  year = {2022},  
}

@phdthesis{dou_thesis_decipherment,
  url = {https://digitallibrary.usc.edu/Share/61b761151l1kvxj4434b7d1pqovm044r},  
  author = {Qing Dou},  
  title = {Beyond parallel data: decipherment for better quality machine translation},
  year = {2015},  
}

@phdthesis{ravi_thesis_deciphering_natural_language,
  url = {https://digitallibrary.usc.edu/Share/ib8lk8pl147gtfg145ed40p13il7o65v},  
  author = {Sujith Ravi},  
  title = {Deciphering natural language},
  year = {2011},  
}

@misc{knight_decipherment_tutorial,
  url = {https://kevincrawfordknight.github.io/extra/acl-tutorial-13-decipher-final.pdf},  
  author = {Kevin Knight},  
  title = {ACL Tutorial on Decipherment},  
  year = {2013},  
}


﻿@Article{Assael2022,
author={Assael, Yannis
and Sommerschield, Thea
and Shillingford, Brendan
and Bordbar, Mahyar
and Pavlopoulos, John
and Chatzipanagiotou, Marita
and Androutsopoulos, Ion
and Prag, Jonathan
and de Freitas, Nando},
title={Restoring and attributing ancient texts using deep neural networks},
journal={Nature},
year={2022},
month={Mar},
day={01},
volume={603},
number={7900},
pages={280-283},
abstract={Ancient history relies on disciplines such as epigraphy---the study of inscribed texts known as inscriptions---for evidence of the thought, language, society and history of past civilizations1. However, over the centuries, many inscriptions have been damaged to the point of illegibility, transported far from their original location and their date of writing is steeped in uncertainty. Here we present Ithaca, a deep neural network for the textual restoration, geographical attribution and chronological attribution of ancient Greek inscriptions. Ithaca is designed to assist and expand the historian's workflow. The architecture of Ithaca focuses on collaboration, decision support and interpretability. While Ithaca alone achieves 62{\%} accuracy when restoring damaged texts, the use of Ithaca by historians improved their accuracy from 25{\%} to 72{\%}, confirming the synergistic effect of this research tool. Ithaca can attribute inscriptions to their original location with an accuracy of 71{\%} and can date them to less than 30{\thinspace}years of their ground-truth ranges, redating key texts of Classical Athens and contributing to topical debates in ancient history. This research shows how models such as Ithaca can unlock the cooperative potential between artificial intelligence and historians, transformationally impacting the way that we study and write about one of the most important periods in human history.},
issn={1476-4687},
doi={10.1038/s41586-022-04448-z},
url={https://doi.org/10.1038/s41586-022-04448-z}
}



@misc{https://doi.org/10.48550/arxiv.2101.00121,
  doi = {10.48550/ARXIV.2101.00121},
  
  url = {https://arxiv.org/abs/2101.00121},
  
  author = {Hambardzumyan, Karen and Khachatrian, Hrant and May, Jonathan},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {WARP: Word-level Adversarial ReProgramming},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{gowda-may-2020-finding,
    title = "Finding the Optimal Vocabulary Size for Neural Machine Translation",
    author = "Gowda, Thamme  and
      May, Jonathan",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.352",
    doi = "10.18653/v1/2020.findings-emnlp.352",
    pages = "3955--3964",
    abstract = "We cast neural machine translation (NMT) as a classification task in an autoregressive setting and analyze the limitations of both classification and autoregression components. Classifiers are known to perform better with balanced class distributions during training. Since the Zipfian nature of languages causes imbalanced classes, we explore its effect on NMT. We analyze the effect of various vocabulary sizes on NMT performance on multiple languages with many data sizes, and reveal an explanation for why certain vocabulary sizes are better than others.",
}

@misc{https://doi.org/10.48550/arxiv.2211.08684,
  doi = {10.48550/ARXIV.2211.08684},
  
  url = {https://arxiv.org/abs/2211.08684},
  
  author = {He, Andre and Tomlin, Nicholas and Klein, Dan},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Neural Unsupervised Reconstruction of Protolanguage Word Forms},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}
@inproceedings{Knight2011TheCC,
  title={The Copiale Cipher},
  author={Kevin Knight and Be{\'a}ta Megyesi and Christiane Schaefer},
  booktitle={BUCC@ACL},
  year={2011},
url={https://aclanthology.org/W11-1202.pdf},
}
@article{hauer-kondrak-2016-decoding,
    title = "Decoding Anagrammed Texts Written in an Unknown Language and Script",
    author = "Hauer, Bradley  and
      Kondrak, Grzegorz",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "4",
    year = "2016",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q16-1006",
    doi = "10.1162/tacl_a_00084",
    pages = "75--86",
    abstract = "Algorithmic decipherment is a prime example of a truly unsupervised problem. The first step in the decipherment process is the identification of the encrypted language. We propose three methods for determining the source language of a document enciphered with a monoalphabetic substitution cipher. The best method achieves 97{\%} accuracy on 380 languages. We then present an approach to decoding anagrammed substitution ciphers, in which the letters within words have been arbitrarily transposed. It obtains the average decryption word accuracy of 93{\%} on a set of 50 ciphertexts in 5 languages. Finally, we report the results on the Voynich manuscript, an unsolved fifteenth century cipher, which suggest Hebrew as the language of the document.",
}

@article{Dovbnia2022AutomaticLI,
  title={Automatic Language Identification for Celtic Texts},
  author={Olha Dovbnia and Anna Wr'oblewska},
  journal={ArXiv},
  year={2022},
  volume={abs/2203.04831},
  url={https://www.semanticscholar.org/paper/Automatic-Language-Identification-for-Celtic-Texts-Dovbnia-Wr'oblewska/7e18a345a72b9ff6d8fd54e8f5a9b92a3ba01298}
}

@article{Jauhiainen2019AutomaticLI,
  title={Automatic Language Identification in Texts: A Survey},
  author={T. Jauhiainen and Marco Lui and Marcos Zampieri and Timothy Baldwin and Krister Lind{\'e}n},
  journal={J. Artif. Intell. Res.},
  year={2019},
  volume={65},
  pages={675-782},
  url={https://www.semanticscholar.org/paper/Automatic-Language-Identification-in-Texts%3A-A-Jauhiainen-Lui/739ffc0c6388b853530ee6987fad2d0cdb9014d9},

}

@inproceedings{Minocha2014SubsegmentalLD,
  title={Subsegmental language detection in Celtic language text},
  author={Akshay Minocha and Francis M. Tyers},
  year={2014}
}

@article{taylornsfcareer,
  title={Modeling Language Evolution via Deep Probabilistic Factorization},
  author={Taylor Berg-Kirkpatrick},
  year={2021},
  url={https://www.nsf.gov/awardsearch/showAward?AWD_ID=2146151&HistoricalAwards=false},
}

@article{Skelton2007METHODSOU,
  title={METHODS OF USING PHYLOGENETIC SYSTEMATICS TO RECONSTRUCT THE HISTORY OF THE LINEAR B SCRIPT},
  author={Christina Michelle Skelton},
  journal={Archaeometry},
  year={2007},
  volume={50},
  pages={158-176},
  url={https://www.semanticscholar.org/paper/METHODS-OF-USING-PHYLOGENETIC-SYSTEMATICS-TO-THE-OF-Skelton/4e35498e0ccd754ad817d0ae3d7e133bbdefd821},
}

@inproceedings{Hall2011LargeScaleCR,
  title={Large-Scale Cognate Recovery},
  author={David Hall and Dan Klein},
  booktitle={EMNLP},
  year={2011},
  url={https://www.semanticscholar.org/paper/Large-Scale-Cognate-Recovery-Hall-Klein/cdbcdd8385885aee863783c45320f526f69e55d1},
}

@article{BouchardCt2013AutomatedRO,
  title={Automated reconstruction of ancient languages using probabilistic models of sound change},
  author={Alexandre Bouchard-C{\^o}t{\'e} and David Leo Wright Hall and Thomas L. Griffiths and Dan Klein},
  journal={Proceedings of the National Academy of Sciences},
  url={https://www.semanticscholar.org/paper/Automated-reconstruction-of-ancient-languages-using-Bouchard-C%C3%B4t%C3%A9-Hall/66a07bc51a53d1d2a85c465a79f9da867a1e383c},
  year={2013},
  volume={110},
  pages={4224 - 4229}
}

@misc{https://doi.org/10.48550/arxiv.2103.16046,
  doi = {10.48550/ARXIV.2103.16046},
  
  url = {https://arxiv.org/abs/2103.16046},
  
  author = {Park, Jiwoong and Cho, Junho and Chang, Hyung Jin and Choi, Jin Young},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Unsupervised Hyperbolic Representation Learning via Message Passing Auto-Encoders},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{Globalsc77:online,
title = {Global-scale phylogenetic linguistic inference from lexical resources | Scientific Data},
url = {https://www.nature.com/articles/sdata2018189#author-information},
}

@misc{https://doi.org/10.48550/arxiv.1909.02197,
  doi = {10.48550/ARXIV.1909.02197},
  
  url = {https://arxiv.org/abs/1909.02197},
  
  author = {Kudugunta, Sneha Reddy and Bapna, Ankur and Caswell, Isaac and Arivazhagan, Naveen and Firat, Orhan},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Investigating Multilingual NMT Representations at Scale},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{https://doi.org/10.48550/arxiv.2104.03869,
  doi = {10.48550/ARXIV.2104.03869},
  
  url = {https://arxiv.org/abs/2104.03869},
  
  author = {Chen, Boli and Fu, Yao and Xu, Guangwei and Xie, Pengjun and Tan, Chuanqi and Chen, Mosha and Jing, Liping},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Probing BERT in Hyperbolic Spaces},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{Hyperbol52:online,
title = {Hyperbolic Embeddings with a Hopefully Right Amount of Hyperbole · Stanford DAWN},
url={https://dawn.cs.stanford.edu/2018/03/19/hyperbolics/},
}

@misc{https://doi.org/10.48550/arxiv.2106.02082,
  doi = {10.48550/ARXIV.2106.02082},
  
  url = {https://arxiv.org/abs/2106.02082},
  
  author = {Yu, Dian and He, Taiqi and Sagae, Kenji},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Language Embeddings for Typology and Cross-lingual Transfer Learning},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Manning2020EmergentLS,
  title={Emergent linguistic structure in artificial neural networks trained by self-supervision},
  author={Christopher D. Manning and Kevin Clark and John Hewitt and Urvashi Khandelwal and Omer Levy},
  journal={Proceedings of the National Academy of Sciences},
  year={2020},
  volume={117},
  pages={30046 - 30054},
  url={https://www.semanticscholar.org/paper/Emergent-linguistic-structure-in-artificial-neural-Manning-Clark/04ef54bd467d5e03dee7b0be601cf06d420bffa0}
}

@misc{https://doi.org/10.48550/arxiv.2002.12005,
  doi = {10.48550/ARXIV.2002.12005},
  
  url = {https://arxiv.org/abs/2002.12005},
  
  author = {Assylbekov, Zhenisbek and Jangeldin, Alibi},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Squashed Shifted PMI Matrix: Bridging Word Embeddings and Hyperbolic Spaces},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{https://doi.org/10.48550/arxiv.2204.12481,
  doi = {10.48550/ARXIV.2204.12481},
  
  url = {https://arxiv.org/abs/2204.12481},
  
  author = {Nurmukhamedov, Sultan and Mach, Thomas and Sheverdin, Arsen and Assylbekov, Zhenisbek},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {From Hyperbolic Geometry Back to Word Embeddings},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{Restorin3:online,
title = {Restoring and attributing ancient texts using deep neural networks | Nature},
url={https://www.nature.com/articles/s41586-022-04448-z#citeas},
}

@misc{NorthEur83:online,
title = {NorthEuraLex - Lexicostatistical Database of Northern Eurasia},
url={http://northeuralex.org/},
}

@misc{Frontier91:online,
title = {Frontiers | Deep Learnability: Using Neural Networks to Quantify Language Similarity and Learnability},
url={https://www.frontiersin.org/articles/10.3389/frai.2020.00043/full},
}

@article{Gamallo2017FromLI,
  title={From language identification to language distance},
  author={Pablo Gamallo and Jos{\'e} Ramom Pichel and I{\~n}aki Alegria},
  journal={Physica A-statistical Mechanics and Its Applications},
  year={2017},
  volume={484},
  pages={152-162},
  url={https://www.semanticscholar.org/paper/From-language-identification-to-language-distance-Gamallo-Pichel/744dec27f5d0e2bb7833bcfbf3ca859e482ca357},
}

@misc{TowardsC42:online,
title = {Towards Computational Lexical Semantic Change Detection},
url={https://languagechange.org/#about},
}

@misc{Hyperbol53:online,
title = {Hyperbolic Geometry to Capture Hierarchical Properties of Words | by Rajwrita Nath | Medium},
url={https://medium.com/@rajwrita/hyperbolic-geometry-to-capture-hierarchical-properties-of-words-57aca80aef5f},
}

@misc{mikucompling,
author = {Mikulyte, Gabija and Gilbert, David},
year = {2020},
month = {01},
pages = {},
title = {An efficient automated data analytics approach to large scale computational comparative linguistics},
url = {https://www.researchgate.net/publication/338989490_An_efficient_automated_data_analytics_approach_to_large_scale_computational_comparative_linguistics},
}

@inproceedings{Samohi2022UsingCP,
  title={Using Cross-Lingual Part of Speech Tagging for Partially Reconstructing the Classic Language Family Tree Model},
  author={Anat Samohi and Daniel Weisberg Mitelman and Kfir Bar},
  booktitle={LCHANGE},
  year={2022},
  url={https://www.semanticscholar.org/paper/Using-Cross-Lingual-Part-of-Speech-Tagging-for-the-Samohi-Mitelman/3feced5e538105040b334883cde6dbf5950033f1}
}

@article{Chiswick2004LinguisticDA,
  title={Linguistic Distance: A Quantitative Measure of the Distance Between English and Other Languages},
  author={Barry R. Chiswick and Paul Washington Miller},
  journal={Journal of Multilingual and Multicultural Development},
  year={2004},
  volume={26},
  pages={1 - 11},
  url={https://www.semanticscholar.org/paper/Linguistic-Distance%3A-A-Quantitative-Measure-of-the-Chiswick-Miller/9d5d973725979cf14798658b2bfe78c11c544652}
}

@misc{LexicalD18,
title = {Lexical Distance Among Languages of Europe 2015 Alternative Transport},
url={https://alternativetransport.wordpress.com/2015/05/05/34/},
}

@inproceedings{Barannikov2022RepresentationTD,
  title={Representation Topology Divergence: A Method for Comparing Neural Network Representations},
  author={S. Barannikov and Ilya Trofimov and Nikita Balabin and Evgeny Burnaev},
  booktitle={ICML},
  year={2022},
url={https://www.semanticscholar.org/paper/Representation-Topology-Divergence%3A-A-Method-for-Barannikov-Trofimov/4756579b2031cc6c6e41a31712b7ef090e88cc5a},
}

@article{Xia2020PredictingPF,
  title={Predicting Performance for Natural Language Processing Tasks},
  author={M. Xia and Antonios Anastasopoulos and Ruochen Xu and Yiming Yang and Graham Neubig},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.00870},
url={https://www.semanticscholar.org/paper/Predicting-Performance-for-Natural-Language-Tasks-Xia-Anastasopoulos/deedb9b61a01d686b28e6034770fccc142e77fab}
}

@misc{https://doi.org/10.48550/arxiv.2006.11239,
  doi = {10.48550/ARXIV.2006.11239},
  
  url = {https://arxiv.org/abs/2006.11239},
  
  author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Denoising Diffusion Probabilistic Models},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{weng2021diffusion,
  title   = "What are diffusion models?",
  author  = "Weng, Lilian",
  journal = "lilianweng.github.io",
  year    = "2021",
  url     = "https://lilianweng.github.io/posts/2021-07-11-diffusion-models/"
}

@article{joshi2020transformers,
author = {Joshi, Chaitanya},
title = {Transformers are Graph Neural Networks},
journal = {The Gradient},
year = {2020},
howpublished = {\url{https://thegradient.pub/transformers-are-gaph-neural-networks/ } },
url={https://thegradient.pub/transformers-are-graph-neural-networks/},
}

@inproceedings{Rieck19a,
  title     = {Neural Persistence: {A} Complexity Measure for Deep Neural Networks Using Algebraic Topology},
  author    = {Bastian Rieck and Matteo Togninalli and Christian Bock and Michael Moor and Max Horn and Thomas Gumbsch and Karsten Borgwardt},
  booktitle = {International Conference on Learning Representations~(ICLR)},
  year      = {2019},
  url       = {https://openreview.net/forum?id=ByxkijC5FQ},
}

@inproceedings{Jakubowski2020TopologyOW,
  title={Topology of Word Embeddings: Singularities Reflect Polysemy},
  author={Alexander Jakubowski and Milica Ga{\vs}i{\'c} and Marcus Zibrowius},
  booktitle={STARSEM},
  year={2020},
  url={https://www.semanticscholar.org/paper/Topology-of-Word-Embeddings%3A-Singularities-Reflect-Jakubowski-Ga%C5%A1i%C4%87/a379e9e5025d3e2e1897b211bca8338bc0155311},
}

@article{Cherniavskii2022AcceptabilityJV,
  title={Acceptability Judgements via Examining the Topology of Attention Maps},
  author={Daniil Cherniavskii and Eduard Tulchinskii and Vladislav Mikhailov and Irina Proskurina and Laida Kushnareva and E. Artemova and S. Barannikov and Irina Piontkovskaya and D. Piontkovski and Evgeny Burnaev},
  journal={ArXiv},
  year={2022},
  volume={abs/2205.09630},
  url={https://www.semanticscholar.org/paper/Acceptability-Judgements-via-Examining-the-Topology-Cherniavskii-Tulchinskii/320a5d32a22287ec80713f9087d1a300703eb970},
}

@article{https://doi.org/10.48550/arxiv.2205.00953,
  doi = {10.48550/ARXIV.2205.00953},
  
  url = {https://arxiv.org/abs/2205.00953},
  
  author = {Chauhan, Jatin and Kaul, Manohar},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {BERTops: Studying BERT Representations under a Topological Lens},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{colombo-etal-2021-automatic,
    title = "Automatic Text Evaluation through the Lens of {W}asserstein Barycenters",
    author = "Colombo, Pierre  and
      Staerman, Guillaume  and
      Clavel, Chlo{\'e}  and
      Piantanida, Pablo",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.817",
    doi = "10.18653/v1/2021.emnlp-main.817",
    pages = "10450--10466",
    abstract = "A new metric BaryScore to evaluate text generation based on deep contextualized embeddings (\textit{e.g.}, BERT, Roberta, ELMo) is introduced. This metric is motivated by a new framework relying on optimal transport tools, \textit{i.e.}, Wasserstein distance and barycenter. By modelling the layer output of deep contextualized embeddings as a probability distribution rather than by a vector embedding; this framework provides a natural way to aggregate the different outputs through the Wasserstein space topology. In addition, it provides theoretical grounds to our metric and offers an alternative to available solutions (\textit{e.g.}, MoverScore and BertScore). Numerical evaluation is performed on four different tasks: machine translation, summarization, data2text generation and image captioning. Our results show that BaryScore outperforms other BERT based metrics and exhibits more consistent behaviour in particular for text summarization.",
}

@article{https://doi.org/10.48550/arxiv.2109.04825,
  doi = {10.48550/ARXIV.2109.04825},
  
  url = {https://arxiv.org/abs/2109.04825},
  
  author = {Kushnareva, Laida and Cherniavskii, Daniil and Mikhailov, Vladislav and Artemova, Ekaterina and Barannikov, Serguei and Bernstein, Alexander and Piontkovskaya, Irina and Piontkovski, Dmitri and Burnaev, Evgeny},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), Algebraic Topology (math.AT), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  
  title = {Artificial Text Detection via Examining the Topology of Attention Maps},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{https://doi.org/10.48550/arxiv.2106.06469,
  doi = {10.48550/ARXIV.2106.06469},
  
  url = {https://proceedings.neurips.cc/paper/2021/file/8fd7f981e10b41330b618129afcaab2d-Paper.pdf},
  
  author = {Zheng, Songzhu and Zhang, Yikai and Wagner, Hubert and Goswami, Mayank and Chen, Chao},
  
  keywords = {Machine Learning (cs.LG), Computational Geometry (cs.CG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Topological Detection of Trojaned Neural Networks},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{haghighi-etal-2008-learning,
    title = "Learning Bilingual Lexicons from Monolingual Corpora",
    author = "Haghighi, Aria  and
      Liang, Percy  and
      Berg-Kirkpatrick, Taylor  and
      Klein, Dan",
    booktitle = "Proceedings of ACL-08: HLT",
    month = jun,
    year = "2008",
    address = "Columbus, Ohio",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P08-1088",
    pages = "771--779",
}

@inproceedings{Huang_2021,
	doi = {10.1109/icassp39728.2021.9413523},
  
	url = {https://doi.org/10.1109%2Ficassp39728.2021.9413523},
  
	year = 2021,
	month = {jun},
  
	publisher = {{IEEE}
},
  
	author = {Ningyuan Teresa Huang and Soledad Villar},
  
	title = {A Short Tutorial on The Weisfeiler-Lehman Test And Its Variants},
  
	booktitle = {{ICASSP} 2021 - 2021 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})}
}

@misc{https://doi.org/10.48550/arxiv.2202.02495,
  doi = {10.48550/ARXIV.2202.02495},
  
  url = {https://arxiv.org/abs/2202.02495},
  
  author = {Chen, Samantha and Lim, Sunhyuk and Mémoli, Facundo and Wan, Zhengchao and Wang, Yusu},
  
  keywords = {Machine Learning (cs.LG), Metric Geometry (math.MG), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  
  title = {Weisfeiler-Lehman meets Gromov-Wasserstein},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1905.00537,
  doi = {10.48550/ARXIV.1905.00537},
  
  url = {https://arxiv.org/abs/1905.00537},
  
  author = {Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},
  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1706.03762,
  doi = {10.48550/ARXIV.1706.03762},
  
  url = {https://arxiv.org/abs/1706.03762},
  
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Attention Is All You Need},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{Radford2019LanguageMA,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019},
url="https://www.semanticscholar.org/paper/Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/9405cc0d6169988371b2755e573cc28650d14dfe"
}

@misc{https://doi.org/10.48550/arxiv.1810.04805,
  doi = {10.48550/ARXIV.1810.04805},
  
  url = {https://arxiv.org/abs/1810.04805},
  
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Zador2019ACO,
  title={A critique of pure learning and what artificial neural networks can learn from animal brains},
  author={Anthony M. Zador},
  journal={Nature Communications},
  year={2019},
  volume={10},
url="https://www.semanticscholar.org/paper/A-critique-of-pure-learning-and-what-artificial-can-Zador/32abbcb3aa75ac34a92624dc779a9f7a82ee981c",
}

@article{Bergomi2019TowardsAT,
  title={Towards a topological–geometrical theory of group equivariant non-expansive operators for data analysis and machine learning},
  author={Mattia G. Bergomi and Patrizio Frosini and Daniela Giorgi and Nicola Quercioli},
  journal={Nature Machine Intelligence},
  year={2019},
  pages={1-11},
  url="https://www.semanticscholar.org/paper/Towards-a-topological%E2%80%93geometrical-theory-of-group-Bergomi-Frosini/3449e962accb5a34c4b1a9346452b08e03bf9f59"
}

@inproceedings{ye-etal-2021-one2set,
    title = "{O}ne2{S}et: {G}enerating Diverse Keyphrases as a Set",
    author = "Ye, Jiacheng  and
      Gui, Tao  and
      Luo, Yichao  and
      Xu, Yige  and
      Zhang, Qi",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.354",
    doi = "10.18653/v1/2021.acl-long.354",
    pages = "4598--4608",
    abstract = "Recently, the sequence-to-sequence models have made remarkable progress on the task of keyphrase generation (KG) by concatenating multiple keyphrases in a predefined order as a target sequence during training. However, the keyphrases are inherently an unordered set rather than an ordered sequence. Imposing a predefined order will introduce wrong bias during training, which can highly penalize shifts in the order between keyphrases. In this work, we propose a new training paradigm One2Set without predefining an order to concatenate the keyphrases. To fit this paradigm, we propose a novel model that utilizes a fixed set of learned control codes as conditions to generate a set of keyphrases in parallel. To solve the problem that there is no correspondence between each prediction and target during training, we propose a K-step label assignment mechanism via bipartite matching, which greatly increases the diversity and reduces the repetition rate of generated keyphrases. The experimental results on multiple benchmarks demonstrate that our approach significantly outperforms the state-of-the-art methods.",
}

@inproceedings{yuan-etal-2019-interactive,
    title = "Interactive Language Learning by Question Answering",
    author = "Yuan, Xingdi  and
      C{\^o}t{\'e}, Marc-Alexandre  and
      Fu, Jie  and
      Lin, Zhouhan  and
      Pal, Chris  and
      Bengio, Yoshua  and
      Trischler, Adam",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1280",
    doi = "10.18653/v1/D19-1280",
    pages = "2796--2813",
    abstract = "Humans observe and interact with the world to acquire knowledge. However, most existing machine reading comprehension (MRC) tasks miss the interactive, information-seeking component of comprehension. Such tasks present models with static documents that contain all necessary information, usually concentrated in a single short substring. Thus, models can achieve strong performance through simple word- and phrase-based pattern matching. We address this problem by formulating a novel text-based question answering task: Question Answering with Interactive Text (QAit). In QAit, an agent must interact with a partially observable text-based environment to gather information required to answer questions. QAit poses questions about the existence, location, and attributes of objects found in the environment. The data is built using a text-based game generator that defines the underlying dynamics of interaction with the environment. We propose and evaluate a set of baseline models for the QAit task that includes deep reinforcement learning agents. Experiments show that the task presents a major challenge for machine reading systems, while humans solve it with relative ease.",
}

@inproceedings{Ct2018TextWorldAL,
  title={TextWorld: A Learning Environment for Text-based Games},
  author={Marc-Alexandre C{\^o}t{\'e} and {\'A}kos K{\'a}d{\'a}r and Xingdi Yuan and Ben A. Kybartas and Tavian Barnes and Emery Fine and James Moore and Matthew J. Hausknecht and Layla El Asri and Mahmoud Adada and Wendy Tay and Adam Trischler},
  booktitle={CGW@IJCAI},
  year={2018}
}

@article{Alabdulkarim2021GoalDirectedSG,
  title={Goal-Directed Story Generation: Augmenting Generative Language Models with Reinforcement Learning},
  author={Amal Alabdulkarim and Winston Wai-Tai Li and Lara J. Martin and Mark O. Riedl},
  journal={ArXiv},
  year={2021},
  volume={abs/2112.08593},
  url={https://www.semanticscholar.org/paper/Goal-Directed-Story-Generation%3A-Augmenting-Language-Alabdulkarim-Li/4ae9648bfa97dfe6a01b8bc2282ae363660856f5},
}

@inproceedings{Ammanabrolu2021LearningKG,
  title={Learning Knowledge Graph-based World Models of Textual Environments},
  author={Prithviraj Ammanabrolu and Mark O. Riedl},
  booktitle={NeurIPS},
  year={2021},
  url={https://www.semanticscholar.org/paper/Learning-Knowledge-Graph-based-World-Models-of-Ammanabrolu-Riedl/c8fc50bc2cd673fa4e5c5ac581f6fe3fcdaf6b8d},
}

@article{Jansen2022ASS,
  title={A Systematic Survey of Text Worlds as Embodied Natural Language Environments},
  author={Peter Alexander Jansen},
  journal={ArXiv},
  year={2022},
  volume={abs/2107.04132},
  url={https://www.semanticscholar.org/paper/A-Systematic-Survey-of-Text-Worlds-as-Embodied-Jansen/d54f0b453f205f68e24e1b3515c846e23aca196f},
}

@article{hausknecht19,
  title={Interactive Fiction Games: A Colossal Adventure},
  author={Hausknecht, Matthew and Ammanabrolu, Prithviraj and C\^ot\'{e} Marc-Alexandre and Yuan Xingdi},
  journal={CoRR},
  year={2019},
  url={http://arxiv.org/abs/1909.05398},
  volume={abs/1909.05398}
}

@misc{https://doi.org/10.48550/arxiv.2106.09578,
  doi = {10.48550/ARXIV.2106.09578},
  
  url = {https://arxiv.org/abs/2106.09578},
  
  author = {Ammanabrolu, Prithviraj and Riedl, Mark O.},
  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Modeling Worlds in Text},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{ammthesis,
  title={Language Learning in Interactive Environments},
  author={Ammanabrolu, Prithviraj},
  url = {https://smartech.gatech.edu/handle/1853/65088},
  year = {2021},
}

@inproceedings{garbe2019storyassembler,
  title={StoryAssembler: an engine for generating dynamic choice-driven narratives},
  author={Garbe, Jacob and Kreminski, Max and Samuel, Ben and Wardrip-Fruin, Noah and Mateas, Michael},
  booktitle={Proceedings of the 14th International Conference on the Foundations of Digital Games},
  pages={1--10},
  year={2019},
  url={https://mkremins.github.io/publications/StoryAssembler.pdf},
}

@inproceedings{mason2019lume,
  title={Lume: a system for procedural story generation},
  author={Mason, Stacey and Stagg, Ceri and Wardrip-Fruin, Noah},
  booktitle={Proceedings of the 14th International Conference on the Foundations of Digital Games},
  pages={1--9},
  year={2019},
  url = {https://eis.ucsc.edu/papers/Mason_Lume.pdf},
}

@article{calderwoodspinning,
  title={Spinning Coherent Interactive Fiction through Foundation Model Prompts},
  author={Calderwood, Alex and Wardrip-Fruin, Noah and Mateas, Michael},
  url = {https://computationalcreativity.net/iccc22/wp-content/uploads/2022/06/ICCC-2022_2L_Calderwood-et-al..pdf},
  year = {2022},

}

@misc{https://doi.org/10.48550/arxiv.2001.10161,
  doi = {10.48550/ARXIV.2001.10161},
  
  url = {https://arxiv.org/abs/2001.10161},
  
  author = {Ammanabrolu, Prithviraj and Cheung, Wesley and Tu, Dan and Broniec, William and Riedl, Mark O.},
  
  keywords = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Bringing Stories Alive: Generating Interactive Fiction Worlds},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@inproceedings{holtzman-etal-2018-learning,
    title = "Learning to Write with Cooperative Discriminators",
    author = "Holtzman, Ari  and
      Buys, Jan  and
      Forbes, Maxwell  and
      Bosselut, Antoine  and
      Golub, David  and
      Choi, Yejin",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1152",
    doi = "10.18653/v1/P18-1152",
    pages = "1638--1649",
    abstract = "Despite their local fluency, long-form text generated from RNNs is often generic, repetitive, and even self-contradictory. We propose a unified learning framework that collectively addresses all the above issues by composing a committee of discriminators that can guide a base RNN generator towards more globally coherent generations. More concretely, discriminators each specialize in a different principle of communication, such as Grice{'}s maxims, and are collectively combined with the base RNN generator through a composite decoding objective. Human evaluation demonstrates that text generated by our model is preferred over that of baselines by a large margin, significantly enhancing the overall coherence, style, and information of the generations.",
}

@inproceedings{mireshghallah-etal-2022-mix,
    title = "Mix and Match: Learning-free Controllable Text Generationusing Energy Language Models",
    author = "Mireshghallah, Fatemehsadat  and
      Goyal, Kartik  and
      Berg-Kirkpatrick, Taylor",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.31",
    doi = "10.18653/v1/2022.acl-long.31",
    pages = "401--415",
    abstract = "Recent work on controlled text generation has either required attribute-based fine-tuning of the base language model (LM), or has restricted the parameterization of the attribute discriminator to be compatible with the base autoregressive LM. In this work, we propose Mix and Match LM, a global score-based alternative for controllable text generation that combines arbitrary pre-trained black-box models for achieving the desired attributes in the generated text without involving any fine-tuning or structural assumptions about the black-box models. We interpret the task of controllable generation as drawing samples from an energy-based model whose energy values are a linear combination of scores from black-box models that are separately responsible for fluency, the control attribute, and faithfulness to any conditioning context. We use a Metropolis-Hastings sampling scheme to sample from this energy-based model using bidirectional context and global attribute features. We validate the effectiveness of our approach on various controlled generation and style-based text revision tasks by outperforming recently proposed methods that involve extra training, fine-tuning, or restrictive assumptions over the form of models.",
}

@misc{https://doi.org/10.48550/arxiv.2106.02736,
  doi = {10.48550/ARXIV.2106.02736},
  
  url = {https://arxiv.org/abs/2106.02736},
  
  author = {Goyal, Kartik and Dyer, Chris and Berg-Kirkpatrick, Taylor},
  
  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Exposing the Implicit Energy Networks behind Masked Language Models via Metropolis--Hastings},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{krause-etal-2021-gedi-generative,
    title = "{G}e{D}i: Generative Discriminator Guided Sequence Generation",
    author = "Krause, Ben  and
      Gotmare, Akhilesh Deepak  and
      McCann, Bryan  and
      Keskar, Nitish Shirish  and
      Joty, Shafiq  and
      Socher, Richard  and
      Rajani, Nazneen Fatema",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.424",
    doi = "10.18653/v1/2021.findings-emnlp.424",
    pages = "4929--4952",
    abstract = "",
}

@inproceedings{Chaffin_2022,
	doi = {10.1145/3477495.3531858},
  
	url = {https://doi.org/10.1145%2F3477495.3531858},
  
	year = 2022,
	month = {jul},
  
	publisher = {{ACM}
},
  
	author = {Antoine Chaffin and Thomas Scialom and Sylvain Lamprier and Jacopo Staiano and Benjamin Piwowarski and Ewa Kijak and Vincent Claveau},
  
	title = {Which Discriminator for Cooperative Text Generation?},
  
	booktitle = {Proceedings of the 45th International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval}
}

@inproceedings{chaffin-etal-2022-ppl,
    title = "{PPL-MCTS}: {C}onstrained Textual Generation Through Discriminator-Guided {MCTS} Decoding",
    author = "Chaffin, Antoine  and
      Claveau, Vincent  and
      Kijak, Ewa",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.215",
    doi = "10.18653/v1/2022.naacl-main.215",
    pages = "2953--2967",
    abstract = "",
}

@inproceedings{chaffin-etal-2022-ppl,
    title = "{PPL-MCTS}: {C}onstrained Textual Generation Through Discriminator-Guided {MCTS} Decoding",
    author = "Chaffin, Antoine  and
      Claveau, Vincent  and
      Kijak, Ewa",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.215",
    doi = "10.18653/v1/2022.naacl-main.215",
    pages = "2953--2967",
    abstract = "Large language models (LM) based on Transformers allow to generate plausible long texts. In this paper, we explore how this generation can be further controlled at decoding time to satisfy certain constraints (e.g. being non-toxic, conveying certain emotions, using a specific writing style, etc.) without fine-tuning the LM.Precisely, we formalize constrained generation as a tree exploration process guided by a discriminator that indicates how well the associated sequence respects the constraint. This approach, in addition to being easier and cheaper to train than fine-tuning the LM, allows to apply the constraint more finely and dynamically.We propose several original methods to search this generation tree, notably the Monte Carlo Tree Search (MCTS) which provides theoretical guarantees on the search efficiency, but also simpler methods based on re-ranking a pool of diverse sequences using the discriminator scores. These methods are evaluated, with automatic and human-based metrics, on two types of constraints and languages: review polarity and emotion control in French and English. We show that discriminator-guided MCTS decoding achieves state-of-the-art results without having to tune the language model, in both tasks and languages. We also demonstrate that other proposed decoding methods based on re-ranking can be really effective when diversity among the generated propositions is encouraged.",
}

@misc{https://doi.org/10.48550/arxiv.2110.07178,
  doi = {10.48550/ARXIV.2110.07178},
  
  url = {https://arxiv.org/abs/2110.07178},
  
  author = {West, Peter and Bhagavatula, Chandra and Hessel, Jack and Hwang, Jena D. and Jiang, Liwei and Bras, Ronan Le and Lu, Ximing and Welleck, Sean and Choi, Yejin},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Symbolic Knowledge Distillation: from General Language Models to Commonsense Models},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@INPROCEEDINGS{8953424,  
author={Corneanu, Ciprian A. and Madadi, Meysam and Escalera, Sergio and Martinez, Aleix M.},  
booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},   
title={What Does It Mean to Learn in Deep Networks? And, How Does One Detect Adversarial Attacks?},   
year={2019},  volume={},  number={},  pages={4752-4761},  doi={10.1109/CVPR.2019.00489}
}

@misc{https://doi.org/10.48550/arxiv.2111.15651,
  doi = {10.48550/ARXIV.2111.15651},
  
  url = {https://arxiv.org/abs/2111.15651},
  
  author = {Synakowski, Stuart and Benitez-Quiroz, Fabian and Martinez, Aleix M.},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Leveraging The Topological Consistencies of Learning in Deep Neural Networks},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{https://doi.org/10.48550/arxiv.2005.00450,
  doi = {10.48550/ARXIV.2005.00450},
  
  url = {https://arxiv.org/abs/2005.00450},
  
  author = {Corneanu, Ciprian and Madadi, Meysam and Escalera, Sergio and Martinez, Aleix},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Computing the Testing Error without a Testing Set},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{https://doi.org/10.48550/arxiv.2111.15651,
  doi = {10.48550/ARXIV.2111.15651},
  
  url = {https://arxiv.org/abs/2111.15651},
  
  author = {Synakowski, Stuart and Benitez-Quiroz, Fabian and Martinez, Aleix M.},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Leveraging The Topological Consistencies of Learning in Deep Neural Networks},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@inproceedings{arora-etal-2022-estimating,
    title = "Estimating the Entropy of Linguistic Distributions",
    author = "Arora, Aryaman  and
      Meister, Clara  and
      Cotterell, Ryan",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-short.20",
    doi = "10.18653/v1/2022.acl-short.20",
    pages = "175--195",
    abstract = "Shannon entropy is often a quantity of interest to linguists studying the communicative capacity of human language. However, entropymust typically be estimated from observed data because researchers do not have access to the underlying probability distribution. While entropy estimation is a well-studied problem in other fields, there is not yet a comprehensive exploration of the efficacy of entropy estimators for use with linguistic data. In this work, we fill this void, studying the empirical effectiveness of different entropy estimators for linguistic distributions. In a replication of two recent information-theoretic linguistic studies, we find evidence that the reported effect size is over-estimated due to over-reliance on poor entropy estimators. We end this paper with a concrete recommendation for the entropy estimators that should be used in future linguistic studies.",
}

@misc{https://doi.org/10.48550/arxiv.2205.01068,
  doi = {10.48550/ARXIV.2205.01068},
  
  url = {https://arxiv.org/abs/2205.01068},
  
  author = {Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and Mihaylov, Todor and Ott, Myle and Shleifer, Sam and Shuster, Kurt and Simig, Daniel and Koura, Punit Singh and Sridhar, Anjali and Wang, Tianlu and Zettlemoyer, Luke},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {OPT: Open Pre-trained Transformer Language Models},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{https://doi.org/10.48550/arxiv.2207.14251,
  doi = {10.48550/ARXIV.2207.14251},
  
  url = {https://arxiv.org/abs/2207.14251},
  
  author = {Elazar, Yanai and Kassner, Nora and Ravfogel, Shauli and Feder, Amir and Ravichander, Abhilasha and Mosbach, Marius and Belinkov, Yonatan and Schütze, Hinrich and Goldberg, Yoav},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Measuring Causal Effects of Data Statistics on Language Model's `Factual' Predictions},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{https://doi.org/10.48550/arxiv.2101.07752,
  doi = {10.48550/ARXIV.2101.07752},
  
  url = {https://arxiv.org/abs/2101.07752},
  
  author = {Pérez-Fernández, David and Gutiérrez-Fandiño, Asier and Armengol-Estapé, Jordi and Villegas, Marta},
  
  keywords = {Machine Learning (cs.LG), Algebraic Topology (math.AT), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  
  title = {Characterizing and Measuring the Similarity of Neural Networks with Persistent Homology},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}
